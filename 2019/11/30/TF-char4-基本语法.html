<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,TensorFlow," />





  <link rel="alternate" href="/atom.xml" title="尤尔小屋" type="application/atom+xml" />






<meta name="description" content="char4-TensorFlow基础入门 TensorFlow是一个面向深度学习算法的科学计算库，内部数据保存在张量Tensor对象中，所有的运算操作都是基于张量进行的">
<meta name="keywords" content="机器学习,TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TF-char4-TF2基本语法">
<meta property="og:url" content="http:&#x2F;&#x2F;www.renpeter.cn&#x2F;2019&#x2F;11&#x2F;30&#x2F;TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html">
<meta property="og:site_name" content="尤尔小屋">
<meta property="og:description" content="char4-TensorFlow基础入门 TensorFlow是一个面向深度学习算法的科学计算库，内部数据保存在张量Tensor对象中，所有的运算操作都是基于张量进行的">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwly1g9fetqxtvij30xy0u01ky.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9fucz7dgxj30p20citay.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9fuil2xp3j30gu082my6.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9g5bpe31rj30ve0rwn2j.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9fwhr3fl0j30ga0biaau.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9g5k7w8o8j31ak0h0q6e.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwgy1g9g5m6oj5aj30z20qwq9n.jpg">
<meta property="og:updated_time" content="2020-06-17T02:55:05.537Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;006tNbRwly1g9fetqxtvij30xy0u01ky.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    
    emojis: {
      className: 'github-emoji'
    }
  };
</script>



  <link rel="canonical" href="http://www.renpeter.cn/2019/11/30/TF-char4-基本语法.html"/>





  <title>TF-char4-TF2基本语法 | 尤尔小屋</title>
  








</head>


<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

   <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/pidada" target="_blank" rel="noopener"><img style="position: absolute; top: 0; right: 0; border: 0" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_white_ffffff.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">尤尔小屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Stay Foolish Stay Hungry</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-links">
          <a href="/links/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-link"></i> <br />
            
            links
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.renpeter.cn/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PiQianChao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cunshang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="尤尔小屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">TF-char4-TF2基本语法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-30T16:05:58+08:00">
                2019-11-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/TF/" itemprop="url" rel="index">
                    <span itemprop="name">TF</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/11/30/TF-char4-基本语法.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.4k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>char4-TensorFlow基础入门</p>
<p><code>TensorFlow</code>是一个面向深度学习算法的科学计算库，内部数据保存在张量Tensor对象中，所有的运算操作都是基于张量进行的</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9fetqxtvij30xy0u01ky.jpg" alt=""></p>
<a id="more"></a>
<h3 id="数据类型">数据类型</h3>
<h4 id="数值类型">数值类型</h4>
<p>数值类型的张量是<code>TF</code>的主要数据载体，包含：</p>
<ol>
<li>标量<code>Scalar</code>，单个的实数，维度是0，形状<code>shape</code>是<code>[]</code></li>
<li>向量<code>Vector</code>，<code>n</code>个实数的有序集合，通过中括号包裹，例如<code>[1,2,4,5,3]</code>，维数是1，长度不定，<code>shape</code>为n</li>
<li>矩阵<code>Matrix</code>，m行n列实数的有序集合，shape为[m,n]</li>
<li>张量是所有维度数（dim&gt;2）的数组的统称，每个维度也称之为轴<code>Axis</code>。通常将标量、向量、矩阵也统称为张量；张量的维度和形状自行判断</li>
</ol>
<h5 id="标量">标量</h5>
<p>创建标量的关键字是constant，必须通过TF规定的方式去创建张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = <span class="number">2</span>  <span class="comment"># python形式</span></span><br><span class="line">b = tf.constant(<span class="number">2.0</span>)  <span class="comment"># 这才是TF形式</span></span><br><span class="line">c = tf.constant([<span class="number">1</span>,<span class="number">2.0</span>,<span class="number">3.7</span>])</span><br><span class="line"></span><br><span class="line">tf.is_true(b)  <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<p>返回值中几个具体信息：</p>
<ul>
<li>id：内部索引对象的编号</li>
<li>shape：张量的形状</li>
<li>dtype：张量的数值精度</li>
</ul>
<h5 id="向量">向量</h5>
<p>向量的定义必须通过<code>List</code>类型转递给<code>tf.constant</code>函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1.0</span>])  <span class="comment"># 即使是一个元素也是如此</span></span><br><span class="line">b = tf.constant([<span class="number">1.0</span>, <span class="number">2.4</span>, <span class="number">4.5</span>])</span><br></pre></td></tr></table></figure>
<h5 id="矩阵">矩阵</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">                 [<span class="number">3</span>,<span class="number">4</span>]])  <span class="comment"># 2维</span></span><br><span class="line"></span><br><span class="line">b = tf.constant([[[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]],</span><br><span class="line">                 [[<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>]]])  <span class="comment"># 3维</span></span><br></pre></td></tr></table></figure>
<h4 id="字符串类型">字符串类型</h4>
<p>字符串类型Strings类型的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="string">"hello tensorflow"</span>)</span><br></pre></td></tr></table></figure>
<p>tf.strings模块中提供了常见的工具函数：</p>
<ul>
<li>join</li>
<li>length</li>
<li>split</li>
</ul>
<h4 id="布尔类型">布尔类型</h4>
<p>TF中支持布尔类型的张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf中布尔类型和Python的中布尔类型是不等同的</span></span><br><span class="line">b =  tf.constant(<span class="literal">True</span>)</span><br><span class="line">b == <span class="literal">True</span>     <span class="comment"># 结果是False</span></span><br></pre></td></tr></table></figure>
<h3 id="数值精度">数值精度</h3>
<h4 id="精度设置和获取">精度设置和获取</h4>
<p>TF支持不同类型的精度，Bit位数越长，精度越高，同时占用的内存空间越大。</p>
<ul>
<li>tf.int16/32/64</li>
<li>tf.float16/32/64；<code>tf.float64</code>就是<code>tf.double</code></li>
</ul>
<p>需要注意的点：</p>
<ol>
<li>高精度转低精度可能会报错</li>
<li>对于浮点数，高精度的张量可以表示更精准的数据</li>
<li>实际中，一般使用<code>tf.int32</code>和<code>tf.float32</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建张量的时候指定精度</span></span><br><span class="line">tf.constant(<span class="number">12345678</span>, dtype=tf.int32)</span><br><span class="line">tf.constant(np.pi, dtype=tf.float64)</span><br></pre></td></tr></table></figure>
<p>通过张量的<code>dtype</code>属性可以获取张量的精度</p>
<h4 id="类型转换">类型转换</h4>
<p>通过<code>tf.cast</code>函数进行转换，需要注意的地方：</p>
<ul>
<li>保证转换操作的合法性，比如高精度转低精度，可能发生溢出现象</li>
<li>布尔型和整形之间可以转换</li>
<li>False默认是0，True表示1；其他非0数字默认是1</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line">tf.cast(a, tf.bool)  <span class="comment"># 1,0</span></span><br></pre></td></tr></table></figure>
<h4 id="待优化张量">待优化张量</h4>
<p>有些张量是<strong>需要计算梯度</strong>，因此产生了需要计算待优化的张量，<strong>专门用来支持梯度信息的记录</strong>，使用的函数是<code>tf.Variable</code>。</p>
<p><code>tf.Variable</code>类型在普通的张量类型基础上添加了name 、trainable等属性来支持计算的构建。</p>
<p>梯度的计算会消耗大量的资源，且会自动更新相关参数。</p>
<ul>
<li>
<p>不需要优化的张量，比如神经网络的输入X，<code>tf.Variable</code>不进行封装</p>
</li>
<li>
<p>需要优化的张量，比如神经网络的权重和偏置等，通过<code>tf.Variable</code>进行把包裹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = tf.Variable(a)</span><br><span class="line">b.name, b.trainable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接创建</span></span><br><span class="line">c = tf.Variable([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>name属性表示计算图中的名称；</li>
<li>trainable表示张量是否需要优化，默认是True,表示优化</li>
</ul>
</li>
</ul>
<h3 id="创建张量">创建张量</h3>
<h4 id="从Numpy、List对象创建">从Numpy、List对象创建</h4>
<p>numpy中的array数组和Python中的list都可以直接用来创建张量，通过<code>tf.convert_to_tensor</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">tf.convert_to_tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">tf.convert_to_tensor(np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<p>numpy中默认使用的是64-bit精度，转到TF中使用的是<code>tf.float64</code></p>
<h4 id="创建全0、全1张量">创建全0、全1张量</h4>
<p>几个函数记住即可，<code>like</code>只是创建形状相同的张量：</p>
<ul>
<li>tf.ones()/tf.ones_like()</li>
<li>tf.zeros()/tf.zeros_like()</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">a = tf.zeros([<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line">b = tf.ones_like(a)  <span class="comment"># 形状相同</span></span><br></pre></td></tr></table></figure>
<h4 id="自定义数值张量">自定义数值张量</h4>
<p>在创建张量的时候，可以指定初始值：tf.fill(shape, vlaue)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.fill([<span class="number">2</span>,<span class="number">3</span>], <span class="number">-1</span>)  <span class="comment"># 形状为2*3，值全部是-1</span></span><br></pre></td></tr></table></figure>
<h4 id="创建已知分布的张量">创建已知分布的张量</h4>
<p>正态分布和均匀分布是最常见的。</p>
<ul>
<li>正态分布：卷积神经网络中卷积核张量W，<code>tf.random.normal(shape, mean=0.0, stddev=1.0)</code></li>
<li>均匀分布：对抗网络中的隐藏层z一般采样自均匀分布，<code>tf.random.uniform(shape, minval=0,maxval=None,dtype=float32)</code></li>
</ul>
<p>注意：如果均匀分布中采样的是整数类型，<strong>必须指定maxval和数据类型</strong></p>
<h4 id="创建序列">创建序列</h4>
<p>创建序列类型的张量是通过函数<code>tf.range()</code>，标准的格式为:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.range(start,end,delta=<span class="number">1</span>)  <span class="comment"># 含头不含尾，delta为步长</span></span><br></pre></td></tr></table></figure>
<h3 id="张量的应用">张量的应用</h3>
<h4 id="标量-v2">标量</h4>
<p>标量的应用主要是误差值的表示、各种测量指标的表示，入精确度、精度、召回率等</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9fucz7dgxj30p20citay.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">out = tf.random.uniform(<span class="number">4</span>,<span class="number">10</span>)  <span class="comment"># 随机模拟网络输出</span></span><br><span class="line">y = tf.constant([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]) <span class="comment"># 随机构造样本真实输出标签</span></span><br><span class="line">y = tf.one_hot(y, depth=<span class="number">10</span>)  <span class="comment"># 转成热编码</span></span><br><span class="line">loss = tf.keras.losses.mse(y, out)  <span class="comment"># 计算MSE</span></span><br><span class="line">loss = tf.reduce_mean(loss)  <span class="comment"># 平均MSE</span></span><br><span class="line">print(mse)</span><br></pre></td></tr></table></figure>
<h4 id="向量-v2">向量</h4>
<p>在全连接层和卷积神经网络中，偏置b就是向量$b=[b_!,b_2]^T$</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9fuil2xp3j30gu082my6.jpg" alt=""></p>
<p>通过高层结口Dense()方式创建地网络层，张量W和b存储在类的内部，由类自动创建。</p>
<ul>
<li>通过全连接层的bias成员查看偏置b</li>
<li>类的偏置bias初始值全部是0</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fc = layers.Dense(<span class="number">3</span>)  <span class="comment"># 创建一层Wx+b，输出节点为3</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">fc.bias  <span class="comment"># 查看偏置</span></span><br></pre></td></tr></table></figure>
<h4 id="矩阵-v2">矩阵</h4>
<p>矩阵也是非常常见的张量类型，比如全连接层的批量输入$X=[b,d_{in}]$，其中b表示的是输入样本的个数，即<code>batch size</code>，$d_{in}$表示的是输入特征的长度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w = tf.constant([<span class="number">3</span>,<span class="number">4</span>])  <span class="comment"># 定义两个张量</span></span><br><span class="line">b = tf.constant([<span class="number">3</span>])</span><br><span class="line">o = x@w + b  <span class="comment"># 执行X@W+b</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>$X@W+b$叫做线性层，也称之为全连接层，通过<code>Dense</code>类直接实现。</p>
</li>
<li>
<p>通过全连接层的<code>kernel</code>属性查看权重矩阵$W$</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fc = layers.Dense(<span class="number">3</span>)  <span class="comment"># 定义全连接层的输出节点为3</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>))  <span class="comment"># 定义全连接层的输入节点为4</span></span><br><span class="line">fc.kernel <span class="comment"># 查看权重矩阵</span></span><br></pre></td></tr></table></figure>
<h4 id="3维张量">3维张量</h4>
<p>三维的张量一个典型应用是表示序列信号，它的格式是<code>𝑋 = [𝑏, 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛, 𝑓𝑒𝑎𝑡𝑢𝑟𝑒 𝑙𝑒𝑛]</code></p>
<ul>
<li>𝑏表示序列信号的数量</li>
<li>𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛表示时间维度上的采样点数</li>
<li>𝑓𝑒𝑎𝑡𝑢𝑟𝑒 𝑙𝑒𝑛表示每个点的特征长度</li>
</ul>
<h4 id="4维张量">4维张量</h4>
<p>4维张量在卷积神经网络中应用的非常广泛，它用于保存特征图<code>Feature maps</code>数据， 格式一般定义为<code>[b,h,w,c]</code></p>
<ul>
<li>b表示输入的数量</li>
<li>h/w表示特征图的高宽</li>
<li>c表示特征图的通道数量</li>
</ul>
<blockquote>
<p>对于含有 RGB 3 个通道的彩色图片，每张图片包含了 h 行 w 列像素点，每个点需要 3 个数 值表示 RGB 通道的颜色强度，因此一张图片可以表示为[h, w, 3]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建32x32的彩色图片输入，个数为4</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>]) <span class="comment"># 创建卷积神经网络</span></span><br><span class="line">layer = layers.Conv2D(<span class="number">16</span>,kernel_size=<span class="number">3</span>) out = layer(x) <span class="comment"># 前向计算</span></span><br><span class="line">out.shape <span class="comment"># 输出大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积核张量也是4维张量，通过kernel属性来查看</span></span><br><span class="line">layer.kernel.shape</span><br></pre></td></tr></table></figure>
<h3 id="索引和切片">索引和切片</h3>
<h4 id="索引">索引</h4>
<ol>
<li>从0开始</li>
<li>两种方式
<ol>
<li><code>[i][j][k]...</code></li>
<li><code>[i,j,k,…]</code></li>
</ol>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">x[<span class="number">0</span>]</span><br><span class="line">x[<span class="number">0</span>][<span class="number">1</span>][<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h4 id="切片">切片</h4>
<p>通过<code>𝑠𝑡𝑎𝑟𝑡: 𝑒𝑛𝑑: 𝑠𝑡𝑒𝑝</code>切片方式提取数据</p>
<ul>
<li>含头不含尾</li>
<li>step步长，可以为负数</li>
</ul>
<p>关于<strong>冒号和三个点</strong>的使用：都是表示某个维度上的所有数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">x[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">x[<span class="number">0</span>,::]</span><br><span class="line">x[<span class="number">0</span>, <span class="number">0</span>:<span class="number">28</span>, <span class="number">2</span>:<span class="number">28</span>:<span class="number">2</span>, :]</span><br><span class="line">x[::<span class="number">-2</span>]</span><br><span class="line">x[<span class="number">0</span>:<span class="number">2</span>,...,<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<h3 id="维度变换">维度变换</h3>
<p>线性层的批量形式<br>
$$<br>
Y=X@W+b<br>
$$<br>
假设：</p>
<ul>
<li>X 包含了 2 个样本，每个样本的特征长度为 4，X 的 shape 为[2,4]</li>
<li>线性层的输出为3个节点，其shape为[4,3]</li>
<li>偏置b的shape为[3]</li>
</ul>
<p>那么不同shape的张量之间如何进行相加？此时，维度变换可以解决</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9g5bpe31rj30ve0rwn2j.jpg" alt=""></p>
<h4 id="改变视图reshape">改变视图reshape</h4>
<h5 id="张量存储">张量存储</h5>
<ol>
<li>张量的存储体现张量在内存上保存为一块连续的存储区域</li>
<li>张量的存储需要人为跟踪</li>
<li>shape中相对靠左的维度称之为<strong>大维度</strong>；相对靠右的维度称之为<strong>小维度</strong></li>
</ol>
<h5 id="张量视图">张量视图</h5>
<p>语法格式为<code>tf.reshape(x, new_shape)</code></p>
<ul>
<li>改变张量的视图始终不改变张量的存储顺序</li>
<li>视图变换需要满足新视图的元素总量与内存区域大小相等即可</li>
<li>为了能够正确恢复出数据，必须保证张量的存储顺序与新视图的维度顺序一致</li>
<li>在实现reshape操作的时候，需要记住张量的存储顺序</li>
<li>参数-1表示长度的自定推导</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">tf.reshape(x, [<span class="number">2</span>,<span class="number">-1</span>])</span><br><span class="line">tf.reshape(x,[<span class="number">2</span>,<span class="number">4</span>,<span class="number">12</span>])</span><br><span class="line">tf.reshape(x,[<span class="number">2</span>,<span class="number">-1</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h4 id="增删维度">增删维度</h4>
<h5 id="增加维度">增加维度</h5>
<ul>
<li>增加一个长度为1的维度相当于是给原数据的维度增加一个新维度，可以理解成改变视图的一种特殊方式</li>
<li>数据的存储方式不变，通过函数<code>tf.expand_dims(x,axis)</code>来实现</li>
<li><code>axis</code>为正，表示在当前维度之前插入一个新维度；<code>axis</code>为负数，在当前维度之后插入一个新维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">28</span>,<span class="number">28</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x = tf.expand_dims(x,axis=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9fwhr3fl0j30ga0biaau.jpg" alt=""></p>
<h5 id="删除维度">删除维度</h5>
<ul>
<li>增加维度的逆操作，<strong>只能删除长度为1的维度</strong></li>
<li>不改变张量的存储方式</li>
<li>通过<code>tf.squeeze(x, axis)</code>来实现</li>
<li>axis表示删除维度的索引号；如果不指定，默认删除全部长度为1的维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x = tf.squeeze(x, axis=<span class="number">2</span>)</span><br><span class="line">tf.squeeze(x)</span><br></pre></td></tr></table></figure>
<h4 id="维度交换">维度交换</h4>
<ul>
<li>改变张量的存储，后续的所有操作都是基于新的存储顺序</li>
<li>改变张量的视图</li>
<li>通过<code>tf.transpose(x, perm)</code>来实现；其中<code>perm</code>表示新维度的顺序list</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line">tf.transpose(x,perm=[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<h4 id="数据复制">数据复制</h4>
<p>通过函数<code>tf.tile(x, multiples)</code>来实现，关于参数<code>multiples</code>：</p>
<ol>
<li>1表示不复制</li>
<li>2表示长度为2倍，即复制1份</li>
<li>3表示长度为3倍，即复制2份；类推</li>
</ol>
<p>复制操作会创建一个新的张量来保存复制后的张量，涉及到大量的IO操作，运算代价大</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">b = tf.constant([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">b = tf.expand_dims(b, axis=<span class="number">0</span>)  <span class="comment"># 插入新维度</span></span><br><span class="line">b = tf.tile(b, multiples=[<span class="number">2</span>,<span class="number">1</span>])  <span class="comment"># axis=0上复制1份</span></span><br><span class="line"></span><br><span class="line">x = tf.range(<span class="number">4</span>)</span><br><span class="line">x = tf.reshape(x, [<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">x = tf.tile(x, multiples=[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment"># 列上复制</span></span><br><span class="line">x = tf.tile(x,multiples=[<span class="number">2</span>,<span class="number">1</span>])  <span class="comment"># 行上复制</span></span><br></pre></td></tr></table></figure>
<h4 id="广播机制Broadcasting">广播机制Broadcasting</h4>
<p>通过函数<code>tf.broadcast_to(x, new_shape)</code>实现</p>
<h5 id="特点">特点</h5>
<ul>
<li>自动扩展，一种轻量级张量复制；在逻辑上扩展张量数据的形状</li>
<li>对于大部 分场景，Broadcasting 机制都能通过优化手段避免实际复制数据而完成逻辑运算</li>
<li>通过优化手段避免实际复制数据而完成逻辑运算，较少计算开销</li>
<li>广播机制不会立即复制数据，逻辑上改变张量的形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line">w = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">3</span>])</span><br><span class="line">y = x@w+b   <span class="comment"># 等价于y = x@w + tf.broadcast_to(b,[2,3])  实现自动广播</span></span><br></pre></td></tr></table></figure>
<h5 id="核心思想">核心思想</h5>
<p>广播机制的核心思想是<strong>普适性</strong>，同一份数据能够适合于不同的位置</p>
<ul>
<li>长度为1，默认数据适合当前维度的其他位置</li>
<li>长度不是1，增加维度后才会才适合</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9g5k7w8o8j31ak0h0q6e.jpg" alt=""></p>
<blockquote>
<p>有些运算可以在处理不同 shape 的张量时，会隐式地调用广播机制</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9g5m6oj5aj30z20qwq9n.jpg" alt=""></p>
<h4 id="数学运算">数学运算</h4>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>//</td>
<td>整除</td>
</tr>
<tr>
<td>%</td>
<td>余除</td>
</tr>
<tr>
<td>tf.power(x,a)，$x**a$</td>
<td>乘方</td>
</tr>
<tr>
<td>tf.square(x)</td>
<td>平方</td>
</tr>
<tr>
<td>tf.sqrt(x)</td>
<td>平方根</td>
</tr>
<tr>
<td>tf.power(a,x)，$a**x$</td>
<td>指数运算</td>
</tr>
<tr>
<td>tf.exp(x)</td>
<td>自然指数</td>
</tr>
<tr>
<td>tf.math.log(x)</td>
<td>自然对数</td>
</tr>
<tr>
<td>$log_ax=\frac{log_ex}{log_ea}$</td>
<td>其他底数的对数</td>
</tr>
</tbody>
</table>
<h4 id="矩阵相乘">矩阵相乘</h4>
<p>两种方式实现：</p>
<ol>
<li>@</li>
<li>tf.matmul(a,b)函数</li>
</ol>
<h3 id="实战-前向传播">实战-前向传播</h3>
<p>采用的手写数字图片集数据：</p>
<ul>
<li>输入节点数是784，第一层节点数是256，第二次层是128，第三层是10</li>
<li>3层神经网络的实现</li>
</ul>
<p>$$<br>
o𝑢𝑡 = 𝑟𝑒𝑙𝑢{𝑟𝑒𝑙𝑢{𝑟𝑒𝑙𝑢[𝑋@𝑊 + 𝑏 ]@𝑊 + 𝑏 }@𝑊 + 𝑏 }<br>
$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  计算每个线性函数的张量参数</span></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将输入数据进行维度变化</span></span><br><span class="line"><span class="comment"># [b, 28, 28] =&gt; [b, 28*28]</span></span><br><span class="line">x = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 非线性函数的计算</span></span><br><span class="line">h1 = x@w1 + tf.broadcast_to(b1, [x.shape[<span class="number">0</span>], <span class="number">256</span>])</span><br><span class="line">h1 = tf.nn.relu(h1)  <span class="comment"># 得到输出函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 完成剩下两个非线性函数</span></span><br><span class="line"><span class="comment"># [b, 256] =&gt; [b, 128]</span></span><br><span class="line">h2 = h1@w2 + b2</span><br><span class="line">h2 = tf.nn.relu(h2)</span><br><span class="line"><span class="comment"># [b, 128] =&gt; [b, 10]</span></span><br><span class="line">out = h2@w3 + b3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方差MSE</span></span><br><span class="line"><span class="comment"># mse = mean(sum(y-out)^2)</span></span><br><span class="line"><span class="comment"># [b, 10]</span></span><br><span class="line">loss = tf.square(y_onehot - out)</span><br><span class="line"><span class="comment"># mean: scalar</span></span><br><span class="line">loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算梯度</span></span><br><span class="line">grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3]</span><br><span class="line"></span><br><span class="line"><span class="comment"># w1 = w1 - lr * w1_grad</span></span><br><span class="line">w1.assign_sub(lr * grads[<span class="number">0</span>])</span><br><span class="line">b1.assign_sub(lr * grads[<span class="number">1</span>])</span><br><span class="line">w2.assign_sub(lr * grads[<span class="number">2</span>])</span><br><span class="line">b2.assign_sub(lr * grads[<span class="number">3</span>])</span><br><span class="line">w3.assign_sub(lr * grads[<span class="number">4</span>])</span><br><span class="line">b3.assign_sub(lr * grads[<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tape.gradient()</code>求出网络参数的梯度信息</li>
<li><code>assign_sub()</code>：实现参数的自我更新</li>
</ul>

      
    </div>
    
    
    

<div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html">TF-char4-TF2基本语法</a></p>
  <p><span>发布时间:</span>2019年11月30日 - 16:11</p>
  <p><span>原始链接:</span><a href="/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html" title="TF-char4-TF2基本语法">http://www.renpeter.cn/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://www.renpeter.cn/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html"  aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
	  $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
	    });
    });  
</script>

      
</div>


    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Coffee or Tea</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="PiQianChao WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/29/%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B05-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" rel="next" title="吴恩达笔记5_神经网络">
                <i class="fa fa-chevron-left"></i> 吴恩达笔记5_神经网络
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/11/30/Golang%E6%80%BB%E7%BB%93.html" rel="prev" title="Golang总结">
                Golang总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/cunshang.jpg"
                alt="PiQianChao" />
            
              <p class="site-author-name" itemprop="name">PiQianChao</p>
              <p class="site-description motion-element" itemprop="description">My Blog</p>
          </div>
            
           <iframe  frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=694660&auto=1&height=66"></iframe>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">541</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">73</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/pidada" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:pichaochao1119@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据类型"><span class="nav-number">1.</span> <span class="nav-text">数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数值类型"><span class="nav-number">1.1.</span> <span class="nav-text">数值类型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#标量"><span class="nav-number">1.1.1.</span> <span class="nav-text">标量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#向量"><span class="nav-number">1.1.2.</span> <span class="nav-text">向量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#矩阵"><span class="nav-number">1.1.3.</span> <span class="nav-text">矩阵</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#字符串类型"><span class="nav-number">1.2.</span> <span class="nav-text">字符串类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#布尔类型"><span class="nav-number">1.3.</span> <span class="nav-text">布尔类型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数值精度"><span class="nav-number">2.</span> <span class="nav-text">数值精度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#精度设置和获取"><span class="nav-number">2.1.</span> <span class="nav-text">精度设置和获取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#类型转换"><span class="nav-number">2.2.</span> <span class="nav-text">类型转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#待优化张量"><span class="nav-number">2.3.</span> <span class="nav-text">待优化张量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建张量"><span class="nav-number">3.</span> <span class="nav-text">创建张量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#从Numpy、List对象创建"><span class="nav-number">3.1.</span> <span class="nav-text">从Numpy、List对象创建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建全0、全1张量"><span class="nav-number">3.2.</span> <span class="nav-text">创建全0、全1张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义数值张量"><span class="nav-number">3.3.</span> <span class="nav-text">自定义数值张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建已知分布的张量"><span class="nav-number">3.4.</span> <span class="nav-text">创建已知分布的张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建序列"><span class="nav-number">3.5.</span> <span class="nav-text">创建序列</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#张量的应用"><span class="nav-number">4.</span> <span class="nav-text">张量的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#标量-v2"><span class="nav-number">4.1.</span> <span class="nav-text">标量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#向量-v2"><span class="nav-number">4.2.</span> <span class="nav-text">向量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#矩阵-v2"><span class="nav-number">4.3.</span> <span class="nav-text">矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3维张量"><span class="nav-number">4.4.</span> <span class="nav-text">3维张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4维张量"><span class="nav-number">4.5.</span> <span class="nav-text">4维张量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#索引和切片"><span class="nav-number">5.</span> <span class="nav-text">索引和切片</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#索引"><span class="nav-number">5.1.</span> <span class="nav-text">索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切片"><span class="nav-number">5.2.</span> <span class="nav-text">切片</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#维度变换"><span class="nav-number">6.</span> <span class="nav-text">维度变换</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#改变视图reshape"><span class="nav-number">6.1.</span> <span class="nav-text">改变视图reshape</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#张量存储"><span class="nav-number">6.1.1.</span> <span class="nav-text">张量存储</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#张量视图"><span class="nav-number">6.1.2.</span> <span class="nav-text">张量视图</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#增删维度"><span class="nav-number">6.2.</span> <span class="nav-text">增删维度</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#增加维度"><span class="nav-number">6.2.1.</span> <span class="nav-text">增加维度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#删除维度"><span class="nav-number">6.2.2.</span> <span class="nav-text">删除维度</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#维度交换"><span class="nav-number">6.3.</span> <span class="nav-text">维度交换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据复制"><span class="nav-number">6.4.</span> <span class="nav-text">数据复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#广播机制Broadcasting"><span class="nav-number">6.5.</span> <span class="nav-text">广播机制Broadcasting</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#特点"><span class="nav-number">6.5.1.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#核心思想"><span class="nav-number">6.5.2.</span> <span class="nav-text">核心思想</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数学运算"><span class="nav-number">6.6.</span> <span class="nav-text">数学运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#矩阵相乘"><span class="nav-number">6.7.</span> <span class="nav-text">矩阵相乘</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实战-前向传播"><span class="nav-number">7.</span> <span class="nav-text">实战-前向传播</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

	
	
		<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
		<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
		<div class="widget-wrap">
			<h3 class="widget-title">标签云</h3>
			<div id="myCanvasContainer" class="widget tagcloud">
			<canvas width="250" height="250" id="resCanvas" style="width=100%">
				 <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IC/" rel="tag">IC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JJ/" rel="tag">JJ</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Leetcode/" rel="tag">Leetcode</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/" rel="tag">MySQL</a><span class="tag-list-count">50</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/d3/" rel="tag">d3</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dash/" rel="tag">dash</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/" rel="tag">go</a><span class="tag-list-count">42</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/highcharts/" rel="tag">highcharts</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kaggle/" rel="tag">kaggle</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a><span class="tag-list-count">63</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/px/" rel="tag">px</a><span class="tag-list-count">25</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyecharts/" rel="tag">pyecharts</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">45</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/" rel="tag">spider</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlzoo/" rel="tag">sqlzoo</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%92%E8%81%94%E7%BD%91/" rel="tag">互联网</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%A7%E5%93%81/" rel="tag">产品</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8C%BA%E5%9F%9F%E9%93%BE/" rel="tag">区域链</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a><span class="tag-list-count">82</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/" rel="tag">吴恩达</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E9%87%91/" rel="tag">基金</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a><span class="tag-list-count">48</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%88%90%E9%95%BF/" rel="tag">成长</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%95%E8%B5%84/" rel="tag">投资</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag">推荐系统</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a><span class="tag-list-count">86</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" rel="tag">时间序列</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">67</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%9C%B3/" rel="tag">深圳</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E6%BC%82/" rel="tag">深漂</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%9F%E6%B4%BB/" rel="tag">生活</a><span class="tag-list-count">51</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%B5%E5%BD%B1/" rel="tag">电影</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E/" rel="tag">经济</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BE%8E%E9%A3%9F/" rel="tag">美食</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86/" rel="tag">自我管理</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/" rel="tag">计算机</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E8%90%A5/" rel="tag">运营</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB/" rel="tag">阅读</a><span class="tag-list-count">28</span></li></ul>
			</canvas>
			</div>
		</div>
	

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PiQianChao</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共716.5k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="true"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://pidada.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.renpeter.cn/2019/11/30/TF-char4-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html';
          this.page.identifier = '2019/11/30/TF-char4-基本语法.html';
          this.page.title = 'TF-char4-TF2基本语法';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://pidada.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script>


  




<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


</body>
</html>
