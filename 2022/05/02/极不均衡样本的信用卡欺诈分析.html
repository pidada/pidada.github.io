<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,逻辑回归,异常检测," />





  <link rel="alternate" href="/atom.xml" title="尤尔小屋" type="application/atom+xml" />






<meta name="description" content="非均衡样本下的信用卡欺诈分析 本文是针对一份kaggle上信用卡数据的建模分析，主要内容包含：  理解数据：通过直方图、箱型图等辅助理解数据分布 预处理：归一化和分布情况；数据分割 随机采样：上采样和下采样，主要是欠采样（下采样） 异常检测：如何从数据中找到异常点，并且进行删除 数据建模：利用逻辑回归和神经网络进行建模分析 模型评价：分类模型的多种评价指标">
<meta name="keywords" content="机器学习,逻辑回归,异常检测">
<meta property="og:type" content="article">
<meta property="og:title" content="极不均衡样本的信用卡欺诈分析">
<meta property="og:url" content="http:&#x2F;&#x2F;www.renpeter.cn&#x2F;2022&#x2F;05&#x2F;02&#x2F;%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html">
<meta property="og:site_name" content="尤尔小屋">
<meta property="og:description" content="非均衡样本下的信用卡欺诈分析 本文是针对一份kaggle上信用卡数据的建模分析，主要内容包含：  理解数据：通过直方图、箱型图等辅助理解数据分布 预处理：归一化和分布情况；数据分割 随机采样：上采样和下采样，主要是欠采样（下采样） 异常检测：如何从数据中找到异常点，并且进行删除 数据建模：利用逻辑回归和神经网络进行建模分析 模型评价：分类模型的多种评价指标">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1rhv3eneyj20i609874k.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1riktv05kj21mk0eo42s.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1rimmxpamj21mq0gsdld.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1rio5mnyij20b207yq2w.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1risb25gjj20tn0abdgc.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1s2j9gp3nj21by0s8gr1.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t2g8v1jvj20vu0bejsd.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7iljkzcj21py0fwjvi.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7m9hraxj20an07l3yg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7ncwzhfj20wc0u041c.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7osge3gj20wc07lmxl.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7pptj3cj20wc07lq3f.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7qbgboej20wl0ab750.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7s2bk85j21qw0kwagv.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7u54v5ej20wc0gp750.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7v3za2ij21270b2dhm.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7y6ll57j20wh0mt40s.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1t7zves02j20qi0ecq3r.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1tsbo0bpjj20kb0dwmxk.jpg">
<meta property="og:updated_time" content="2022-05-02T01:09:48.136Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;e6c9d24ely1h1rhv3eneyj20i609874k.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    
    emojis: {
      className: 'github-emoji'
    }
  };
</script>



  <link rel="canonical" href="http://www.renpeter.cn/2022/05/02/极不均衡样本的信用卡欺诈分析.html"/>





  <title>极不均衡样本的信用卡欺诈分析 | 尤尔小屋</title>
  








</head>


<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

   <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/pidada" target="_blank" rel="noopener"><img style="position: absolute; top: 0; right: 0; border: 0" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_white_ffffff.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">尤尔小屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Stay Foolish Stay Hungry</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-links">
          <a href="/links/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-link"></i> <br />
            
            links
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.renpeter.cn/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PiQianChao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cunshang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="尤尔小屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">极不均衡样本的信用卡欺诈分析</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-05-02T09:08:34+08:00">
                2022-5-2
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/kaggle/" itemprop="url" rel="index">
                    <span itemprop="name">kaggle</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2022/05/02/极不均衡样本的信用卡欺诈分析.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  28
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="非均衡样本下的信用卡欺诈分析">非均衡样本下的信用卡欺诈分析</h2>
<p>本文是针对一份kaggle上信用卡数据的建模分析，主要内容包含：</p>
<ul>
<li>理解数据：通过直方图、箱型图等辅助理解数据分布</li>
<li>预处理：归一化和分布情况；数据分割</li>
<li>随机采样：上采样和下采样，主要是欠采样（下采样）</li>
<li>异常检测：如何从数据中找到异常点，并且进行删除</li>
<li>数据建模：利用逻辑回归和神经网络进行建模分析</li>
<li>模型评价：分类模型的多种评价指标</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1rhv3eneyj20i609874k.jpg" alt=""></p>
<a id="more"></a>
<p>原notebook地址为：<a href="https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets/notebook" target="_blank" rel="noopener">https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets/notebook</a></p>
<blockquote>
<p>所谓的【非均衡】：信用卡数据中<strong>欺诈</strong>和<strong>非欺诈</strong>的比例是不均衡的，肯定是非欺诈的比例占据绝大多数。本文提供一种方法：如何处理这种极度不均衡的数据</p>
</blockquote>
<h2 id="导入库">导入库</h2>
<p>导入各种库和包：绘图、特征工程、降维、分类模型、评价指标相关等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> plotly_express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"><span class="comment"># 子图</span></span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> mpatches</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment"># 降维</span></span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, TruncatedSVD</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">"font.sans-serif"</span>]=[<span class="string">"SimHei"</span>] <span class="comment">#设置字体</span></span><br><span class="line">plt.rcParams[<span class="string">"axes.unicode_minus"</span>]=<span class="literal">False</span> <span class="comment">#正常显示负号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征工程相关的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> imblearn.pipeline <span class="keyword">import</span> make_pipeline <span class="keyword">as</span> imbalanced_make_pipeline</span><br><span class="line"><span class="comment"># 上采样</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="comment"># 欠采样</span></span><br><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> NearMiss</span><br><span class="line"><span class="keyword">from</span> imblearn.metrics <span class="keyword">import</span> classification_report_imbalanced</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report</span><br><span class="line"><span class="comment"># 统计数量</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="基本信息">基本信息</h2>
<p>读取数据，查看基本信息</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1riktv05kj21mk0eo42s.jpg" alt=""></p>
<p>数据的形状如下：</p>
<p>In [3]:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.shape</span></span><br></pre></td></tr></table></figure>
<p>Out[3]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">284807</span>, <span class="number">31</span>)</span><br></pre></td></tr></table></figure>
<p>In [4]:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 缺失值的最大值</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.isnull</span>()<span class="selector-class">.sum</span>()<span class="selector-class">.max</span>()</span><br></pre></td></tr></table></figure>
<p>Out[4]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure>
<p><strong>结果表明是没有缺失值的</strong>。</p>
<p>下面是查看数据中字段的相关类型，我们发现有30个float64类型，1个int64类型</p>
<p>In [5]:</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.value<span class="constructor">_counts(<span class="params">df</span>.<span class="params">dtypes</span>)</span></span><br></pre></td></tr></table></figure>
<p>Out[5]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">float</span>64    <span class="number">30</span></span><br><span class="line"><span class="built_in">int</span>64       <span class="number">1</span></span><br><span class="line">dtype: <span class="built_in">int</span>64</span><br></pre></td></tr></table></figure>
<p>In [6]:</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">columns</span> = df.<span class="built_in">columns</span></span><br><span class="line"><span class="built_in">columns</span></span><br></pre></td></tr></table></figure>
<p>Out[6]:</p>
<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Index</span>([<span class="string">'Time'</span>, <span class="string">'V1'</span>, <span class="string">'V2'</span>, <span class="string">'V3'</span>, <span class="string">'V4'</span>, <span class="string">'V5'</span>, <span class="string">'V6'</span>, <span class="string">'V7'</span>, <span class="string">'V8'</span>, <span class="string">'V9'</span>, <span class="string">'V10'</span>,</span><br><span class="line">       <span class="string">'V11'</span>, <span class="string">'V12'</span>, <span class="string">'V13'</span>, <span class="string">'V14'</span>, <span class="string">'V15'</span>, <span class="string">'V16'</span>, <span class="string">'V17'</span>, <span class="string">'V18'</span>, <span class="string">'V19'</span>, <span class="string">'V20'</span>,</span><br><span class="line">       <span class="string">'V21'</span>, <span class="string">'V22'</span>, <span class="string">'V23'</span>, <span class="string">'V24'</span>, <span class="string">'V25'</span>, <span class="string">'V26'</span>, <span class="string">'V27'</span>, <span class="string">'V28'</span>, <span class="string">'Amount'</span>,</span><br><span class="line">       <span class="string">'Class'</span>],</span><br><span class="line">      dtype=<span class="string">'object'</span>)</span><br></pre></td></tr></table></figure>
<p>查看数据的统计信息：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.describe</span>()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1rimmxpamj21mq0gsdld.jpg" alt=""></p>
<h2 id="正负样本不均衡">正负样本不均衡</h2>
<p>In [8]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">"Class"</span>].value_counts(<span class="attribute">normalize</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Out[8]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>    <span class="number">0.998273</span>  <span class="comment"># 不欺诈</span></span><br><span class="line"><span class="number">1</span>    <span class="number">0.001727</span>  <span class="comment"># 欺诈</span></span><br><span class="line">Name: Class, dtype: float64</span><br></pre></td></tr></table></figure>
<p>我们发现属于0类的样本远高于属于1的样本，<strong>非常地不均衡</strong>。这就是本文重点关注的问题。</p>
<p>In [9]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">colors = [<span class="string">"red"</span>, <span class="string">"blue"</span>]</span><br><span class="line"></span><br><span class="line">sns.countplot(<span class="string">"Class"</span>, <span class="attribute">data</span>=df, <span class="attribute">palette</span>=colors)</span><br><span class="line">plt.title(<span class="string">"Class Distributions \n (0-No Fraud &amp; 1-Fraud)"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1rio5mnyij20b207yq2w.jpg" alt=""></p>
<p>通过柱状图也能够明显观察到<strong>非欺诈-0 和 欺诈-1的比例是极度不均衡的</strong>。</p>
<h2 id="查看特征分布">查看特征分布</h2>
<p>部分特征的分布，发现存在偏态状况：</p>
<h3 id="直方图分布">直方图分布</h3>
<p>In [10]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">amount_val = df[<span class="string">"Amount"</span>].values</span><br><span class="line">time_val = df[<span class="string">"Time"</span>].values</span><br><span class="line"></span><br><span class="line">sns.distplot(amount_val, ax=ax[<span class="number">0</span>], color=<span class="string">"r"</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">"Amount"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlim([min(amount_val), max(amount_val)])  <span class="comment"># 设置范围</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.distplot(time_val, ax=ax[<span class="number">1</span>], color=<span class="string">"b"</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">"Time"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlim([min(time_val), max(time_val)])  <span class="comment"># 设置范围</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1risb25gjj20tn0abdgc.jpg" alt=""></p>
<p>观察两个字段Amount和Time在不同取值下的分布情况，发现：</p>
<ol>
<li>Amount的偏态现象严重，极大多数的数据集中在左侧</li>
<li>Time中，数据主要集中在两个阶段</li>
</ol>
<h3 id="特征分布箱型图">特征分布箱型图</h3>
<p>查看每个特征取值的箱型图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两个基本参数：设置行、列</span></span><br><span class="line">fig = make_subplots(rows=<span class="number">5</span>, cols=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(parameters):</span><br><span class="line">    r = i // <span class="number">6</span> + <span class="number">1</span></span><br><span class="line">    c = (i+<span class="number">1</span>) % <span class="number">6</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> c == <span class="number">0</span>:</span><br><span class="line">        fig.add_trace(go.Box(y=df[v].tolist(),name=v),</span><br><span class="line">                 row=r, col=<span class="number">6</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fig.add_trace(go.Box(y=df[v].tolist(),name=v),</span><br><span class="line">                 row=r, col=c)</span><br><span class="line"></span><br><span class="line">fig.update_layout(width=<span class="number">800</span>, height=<span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1s2j9gp3nj21by0s8gr1.jpg" alt=""></p>
<h2 id="数据预处理">数据预处理</h2>
<h3 id="数据缩放和分布">数据缩放和分布</h3>
<p>针对Amount和Time字段的归一化操作。原始数据中的其他字段已经进行了归一化的操作。</p>
<ul>
<li>StandardScaler：将数据减去均值除以标准差</li>
<li>RobustScaler：如果数据有离群点，有对数据中心化和数据的缩放鲁棒性更强的参数</li>
</ul>
<p>In [13]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, RobustScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># ss = StandardScaler()</span></span><br><span class="line">rs = RobustScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 好方法</span></span><br><span class="line">df[<span class="string">'scaled_amount'</span>] = rs.fit_transform(df[<span class="string">'Amount'</span>].values.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">df[<span class="string">'scaled_time'</span>] = rs.fit_transform(df[<span class="string">'Time'</span>].values.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>In [14]:</p>
<p>删除原始字段，使用归一化后的字段和数据</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-attr">['Amount']</span><span class="selector-class">.values</span><span class="selector-class">.reshape</span>(<span class="selector-tag">-1</span>,1)  # 个人添加</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t2g8v1jvj20vu0bejsd.jpg" alt=""></p>
<h3 id="技巧1：新字段位置">技巧1：新字段位置</h3>
<p>将新生成的字段放在最前面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把两个缩放的字段放在最前面</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、单独提出来</span></span><br><span class="line">scaled_amount = df[<span class="string">'scaled_amount'</span>]</span><br><span class="line">scaled_time = df[<span class="string">'scaled_time'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、删除原字段信息</span></span><br><span class="line">df.drop([<span class="string">'scaled_amount'</span>, <span class="string">'scaled_time'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、插入</span></span><br><span class="line">df.insert(<span class="number">0</span>, <span class="string">'scaled_amount'</span>, scaled_amount)</span><br><span class="line">df.insert(<span class="number">1</span>, <span class="string">'scaled_time'</span>, scaled_time)</span><br></pre></td></tr></table></figure>
<h3 id="分割数据（基于原DataFrame）">分割数据（基于原DataFrame）</h3>
<p>在开始进行随机欠采样之前，我们需要将原始数据进行分割。</p>
<p>尽管我们会对数据进行欠采样和上采样，但是我们希望在测试的时候，仍然是使用原始的数据集（原来的数据顺序）</p>
<p>In [18]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br></pre></td></tr></table></figure>
<p>查看Class中0-no fraud和1-fraud的比例：</p>
<p>In [19]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">"Class"</span>].value_counts(<span class="attribute">normalize</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Out[19]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>    <span class="number">0.998273</span></span><br><span class="line"><span class="number">1</span>    <span class="number">0.001727</span></span><br><span class="line">Name: Class, dtype: <span class="built_in">float</span>64</span><br></pre></td></tr></table></figure>
<p>生成特征数据集X和标签数据y：</p>
<p>In [20]:</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">X</span> = df.drop(<span class="string">"Class"</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="attr">y</span> = df[<span class="string">"Class"</span>]</span><br></pre></td></tr></table></figure>
<p>In [21]:</p>
<h3 id="技巧2：生成随机索引">技巧2：生成随机索引</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">sfk = StratifiedKFold(</span><br><span class="line">    n_splits=<span class="number">5</span>,   <span class="comment"># 生成5份</span></span><br><span class="line">    random_state=<span class="literal">None</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> sfk.split(X,y):</span><br><span class="line">    <span class="comment"># 随机生成的index</span></span><br><span class="line">    print(train_index)</span><br><span class="line">    print(<span class="string">"------------"</span>)</span><br><span class="line">    print(test_index)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据随机生成的索引再生成数据</span></span><br><span class="line">    original_X_train = X.iloc[train_index]</span><br><span class="line">    original_X_test = X.iloc[test_index]</span><br><span class="line"></span><br><span class="line">    original_y_train = y.iloc[train_index]</span><br><span class="line">    original_y_test = y.iloc[test_index]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ <span class="number">30473</span>  <span class="number">30496</span>  <span class="number">31002</span> ... <span class="number">284804</span> <span class="number">284805</span> <span class="number">284806</span>]</span><br><span class="line">------------</span><br><span class="line">[    <span class="number">0</span>     <span class="number">1</span>     <span class="number">2</span> ... <span class="number">57017</span> <span class="number">57018</span> <span class="number">57019</span>]</span><br><span class="line"></span><br><span class="line">[     <span class="number">0</span>      <span class="number">1</span>      <span class="number">2</span> ... <span class="number">284804</span> <span class="number">284805</span> <span class="number">284806</span>]</span><br><span class="line">------------</span><br><span class="line">[ <span class="number">30473</span>  <span class="number">30496</span>  <span class="number">31002</span> ... <span class="number">113964</span> <span class="number">113965</span> <span class="number">113966</span>]</span><br><span class="line"></span><br><span class="line">[     <span class="number">0</span>      <span class="number">1</span>      <span class="number">2</span> ... <span class="number">284804</span> <span class="number">284805</span> <span class="number">284806</span>]</span><br><span class="line">------------</span><br><span class="line">[ <span class="number">81609</span>  <span class="number">82400</span>  <span class="number">83053</span> ... <span class="number">170946</span> <span class="number">170947</span> <span class="number">170948</span>]</span><br><span class="line"></span><br><span class="line">[     <span class="number">0</span>      <span class="number">1</span>      <span class="number">2</span> ... <span class="number">284804</span> <span class="number">284805</span> <span class="number">284806</span>]</span><br><span class="line">------------</span><br><span class="line">[<span class="number">150654</span> <span class="number">150660</span> <span class="number">150661</span> ... <span class="number">227866</span> <span class="number">227867</span> <span class="number">227868</span>]</span><br><span class="line"></span><br><span class="line">[     <span class="number">0</span>      <span class="number">1</span>      <span class="number">2</span> ... <span class="number">227866</span> <span class="number">227867</span> <span class="number">227868</span>]</span><br><span class="line">------------</span><br><span class="line">[<span class="number">212516</span> <span class="number">212644</span> <span class="number">213092</span> ... <span class="number">284804</span> <span class="number">284805</span> <span class="number">284806</span>]</span><br></pre></td></tr></table></figure>
<p>将生成的数据转成numpy数组：</p>
<p>In [22]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">original_Xtrain = original_X_train.values</span><br><span class="line">original_Xtest = original_X_test.values</span><br><span class="line"></span><br><span class="line">original_ytrain = original_y_train.values</span><br><span class="line">original_ytest = original_y_test.values</span><br></pre></td></tr></table></figure>
<p>查看训练集 original_ytrain 和 original_ytest 的唯一值以及每个唯一值所占的比例：</p>
<p>In [23]:</p>
<h3 id="技巧3：数据唯一值及比例">技巧3：数据唯一值及比例</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练集</span></span><br><span class="line"><span class="comment"># 针对的是numpy数组</span></span><br><span class="line">train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>In [24]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(train_counts_label / len(original_ytrain))</span><br><span class="line"></span><br><span class="line">print(test_counts_label / len(original_ytest))</span><br><span class="line">[<span class="number">0.99827076</span> <span class="number">0.00172924</span>]</span><br><span class="line">[<span class="number">0.99827952</span> <span class="number">0.00172048</span>]</span><br></pre></td></tr></table></figure>
<h2 id="欠采样">欠采样</h2>
<h3 id="原理">原理</h3>
<p>欠采样也称之为下采样，主要是通过删除原数据中类别较多的数据，从而和类别少的数据达到平衡，以免造成模型的过拟合。</p>
<h3 id="步骤">步骤</h3>
<ol>
<li>确定数据不平衡度是多少：通过value_counts()来统计，查看每个类别的数量和占比</li>
<li>在本例中一旦我们确定了fraud的数量，我们就需要将no-fraud的数量采样和其相同，形成50%：50%</li>
<li>实施采样之后，随机打乱采样的子样本</li>
</ol>
<h3 id="缺点">缺点</h3>
<p>下采样会造成数据信息的缺失。比如原数据中no-fraud有284315条数据，但是经过欠采样只有492，大量的数据被放弃了。</p>
<h3 id="实施采样">实施采样</h3>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7iljkzcj21py0fwjvi.jpg" alt=""></p>
<p>取出欺诈的数据，同时从非欺诈中取出相同长度的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 欺诈的数据</span></span><br><span class="line">fraud_df = df[df[<span class="string">"Class"</span>] == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从非欺诈的数据中取出相同的长度len(fraud_df)</span></span><br><span class="line">no_fraud_df = df[df[<span class="string">"Class"</span>] == <span class="number">0</span>][:len(fraud_df)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 492+492</span></span><br><span class="line">normal_distributed_df = pd.concat([fraud_df, no_fraud_df])</span><br><span class="line">normal_distributed_df.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次随机打乱数据</span></span><br><span class="line">new_df = normal_distributed_df.sample(frac=<span class="number">1</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>
<h3 id="均匀分布">均匀分布</h3>
<p>现在我们发现样本是均匀的：</p>
<p>In [28]:</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 显示数量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span><span class="type">_df</span>[<span class="string">"Class"</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p>Out[28]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>    <span class="number">492</span></span><br><span class="line"><span class="number">0</span>    <span class="number">492</span></span><br><span class="line">Name: Class, dtype: <span class="built_in">int</span>64</span><br></pre></td></tr></table></figure>
<p>In [29]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示比例</span></span><br><span class="line"></span><br><span class="line">new_df[<span class="string">"Class"</span>].value_counts(<span class="attribute">normalize</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Out[29]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>    <span class="number">0.5</span></span><br><span class="line"><span class="number">0</span>    <span class="number">0.5</span></span><br><span class="line">Name: Class, dtype: <span class="built_in">float</span>64</span><br></pre></td></tr></table></figure>
<p>In [30]:</p>
<p>当我们再次查看数据分布的时候发现：已经是均匀分布了</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(<span class="string">"Class"</span>,</span><br><span class="line">              <span class="attribute">data</span>=new_df,</span><br><span class="line">              <span class="attribute">palette</span>=colors)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"Equally Distributed Classes"</span>, <span class="attribute">fontsize</span>=12)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7m9hraxj20an07l3yg.jpg" alt=""></p>
<h2 id="相关性分析">相关性分析</h2>
<p>相关性分析主要是通过相关系数矩阵来实现的。下面绘制基于原始数据和欠采样数据的相关系数矩阵图：</p>
<h3 id="系数矩阵热力图">系数矩阵热力图</h3>
<p>In [31]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>,<span class="number">1</span>,figsize=(<span class="number">24</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据df</span></span><br><span class="line">corr = df.corr()</span><br><span class="line">sns.heatmap(corr, cmap=<span class="string">"coolwarm_r"</span>,annot_kws=&#123;<span class="string">"size"</span>:<span class="number">20</span>&#125;, ax=ax1)</span><br><span class="line">ax1.set_title(<span class="string">"Imbalanced Correlation Matrix"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 欠采样数据new_df</span></span><br><span class="line">new_corr = new_df.corr()</span><br><span class="line">sns.heatmap(new_corr, cmap=<span class="string">"coolwarm_r"</span>,annot_kws=&#123;<span class="string">"size"</span>:<span class="number">20</span>&#125;, ax=ax2)</span><br><span class="line">ax2.set_title(<span class="string">"SubSample Correlation Matrix"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7ncwzhfj20wc0u041c.jpg" alt=""></p>
<p>小结：</p>
<ul>
<li>正相关：特征V2、V4、V11、V19是正相关的。值越大，结果越可能出现fraud</li>
<li>负相关：特征V17, V14, V12 和 V10 是负相关的；值越小，结果越可能出现fraud</li>
</ul>
<h3 id="箱型图">箱型图</h3>
<p>In [32]:</p>
<p>负相关的特征箱型图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 负相关的数据</span></span><br><span class="line"><span class="comment"># 生成4个子图</span></span><br><span class="line">f, axes = plt.subplots(ncols=<span class="number">4</span>, figsize=(<span class="number">20</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,  <span class="comment"># 分类的类别 0-1</span></span><br><span class="line">            y=<span class="string">"V17"</span>,   <span class="comment"># 选择某个字段进行绘图</span></span><br><span class="line">            data=new_df,   <span class="comment"># 绘图的数据</span></span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">0</span>])  <span class="comment"># 选择某个ax来绘图</span></span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">'V17'</span>)  <span class="comment"># 子图标题</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V14"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">'V14'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V12"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">'V12'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V10"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">3</span>])</span><br><span class="line">axes[<span class="number">3</span>].set_title(<span class="string">'V10'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7osge3gj20wc07lmxl.jpg" alt=""></p>
<p>正相关特征的箱型图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正相关</span></span><br><span class="line">f, axes = plt.subplots(ncols=<span class="number">4</span>, figsize=(<span class="number">20</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V2"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">0</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">'V2'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V4"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">'V4'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V11"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">2</span>])</span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">'V11'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,</span><br><span class="line">            y=<span class="string">"V19"</span>,</span><br><span class="line">            data=new_df,</span><br><span class="line">            palette=colors,</span><br><span class="line">            ax=axes[<span class="number">3</span>])</span><br><span class="line">axes[<span class="number">3</span>].set_title(<span class="string">'V19'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7pptj3cj20wc07lq3f.jpg" alt=""></p>
<h2 id="异常检测">异常检测</h2>
<h3 id="目的">目的</h3>
<p>异常检测的目的主要是：发现数据中的离群点来进行删除。</p>
<h3 id="方法">方法</h3>
<ol>
<li>IQR：我们通过第75个百分位和第25个百分位之间的差异来计算。我们的目标是创建一个超过第75和 25 个百分位的阈值，以防某些实例超过此阈值，如果超过阈值该实例将被删除。</li>
<li>箱型图boxplot：除了很容易看到第 25 和第 75 个百分位数（正方形的两端）之外，还很容易看到极端异常值（超出下限和上限的点）</li>
</ol>
<h3 id="异常值去除权衡">异常值去除权衡</h3>
<p>在通过四分位法删除异常值的时候，我们通过将一个数字（例如1.5）乘以（四分位距）来确定阈值。该阈值越高，检测到的异常值越少，反之检测到的异常值越多。这个比例（例如1.5）我们可以在实际进行控制</p>
<h3 id="特征分布-直方图">特征分布-直方图</h3>
<p>In [34]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看3个特征的分布</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line">f, (ax1, ax2, ax3) = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成绘图数据：numpy数组</span></span><br><span class="line">v14_fraud = new_df[<span class="string">"V14"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>].values</span><br><span class="line">sns.distplot(v14_fraud,   <span class="comment">#  传入数据</span></span><br><span class="line">             ax=ax1,   <span class="comment"># 选择子图</span></span><br><span class="line">             fit=norm,   <span class="comment"># 拟合：正态化</span></span><br><span class="line">             color=<span class="string">"#FB8861"</span>)</span><br><span class="line">ax1.set_title(<span class="string">"V14"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">v12_fraud = new_df[<span class="string">"V12"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>].values</span><br><span class="line">sns.distplot(v12_fraud,</span><br><span class="line">             ax=ax2,</span><br><span class="line">             fit=norm,</span><br><span class="line">             color=<span class="string">"#56F9BB"</span>)</span><br><span class="line">ax2.set_title(<span class="string">"V12"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">v10_fraud = new_df[<span class="string">"V10"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>].values</span><br><span class="line">sns.distplot(v10_fraud,</span><br><span class="line">             ax=ax3,</span><br><span class="line">             fit=norm,</span><br><span class="line">             color=<span class="string">"#C5B3F9"</span>)</span><br><span class="line">ax2.set_title(<span class="string">"V10"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7qbgboej20wl0ab750.jpg" alt=""></p>
<h3 id="技巧4：删除离群点">技巧4：删除离群点</h3>
<p>删除3个特征下的离群点，以V12为例：</p>
<p>In [35]:</p>
<p>第一步先确定上下分位数的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数组</span></span><br><span class="line">v12_fraud = new_df[<span class="string">"V12"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 25%和75%分位数</span></span><br><span class="line">q1, q3 = v12_fraud.quantile(<span class="number">0.25</span>), v12_fraud.quantile(<span class="number">0.75</span>)</span><br><span class="line">iqr = q3 - q1</span><br></pre></td></tr></table></figure>
<p>In [36]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确定上下限</span></span><br><span class="line">v12_cut_off = iqr * <span class="number">1.5</span></span><br><span class="line">v12_lower = q1 - v12_cut_off</span><br><span class="line">v12_upper = q3 + v12_cut_off</span><br><span class="line"></span><br><span class="line">print(v12_lower)</span><br><span class="line">print(v12_upper)</span><br><span class="line"></span><br><span class="line"><span class="number">-17.25930926645337</span></span><br><span class="line"><span class="number">5.597044719256134</span></span><br></pre></td></tr></table></figure>
<p>In [37]:</p>
<p>找出满足要求的离群点的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确定离群点</span></span><br><span class="line">outliers = [x <span class="keyword">for</span> x <span class="keyword">in</span> v12_fraud <span class="keyword">if</span> x &lt; v12_lower <span class="keyword">or</span> x &gt; v12_upper]</span><br><span class="line"></span><br><span class="line">print(outliers)</span><br><span class="line">print(<span class="string">"------------"</span>)</span><br><span class="line">print(<span class="string">"离群点数量："</span>,len(outliers))</span><br><span class="line">[<span class="number">-17.6316063138707</span>, <span class="number">-17.7691434633638</span>, <span class="number">-18.6837146333443</span>,</span><br><span class="line"><span class="number">-18.5536970096458</span>, <span class="number">-18.0475965708216</span>, <span class="number">-18.4311310279993</span>]</span><br><span class="line">------------</span><br><span class="line">离群点数量： <span class="number">6</span></span><br></pre></td></tr></table></figure>
<p>对单个列字段的数据执行下面删除离群点的操作：</p>
<p>In [38]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 技巧：如何删除异常值</span></span><br><span class="line">new_df = new_df.drop(new_df[(new_df[<span class="string">"V12"</span>] &gt; v12_upper) | (new_df[<span class="string">"V12"</span>] &lt; v12_lower)].index)</span><br><span class="line">new_df</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7s2bk85j21qw0kwagv.jpg" alt=""></p>
<p>对其他的特征执行相同的操作：</p>
<p>可以看到：欠采样之后的数据原本是984，现在变成了978条数据，删除了6个离群点的数据</p>
<p>In [39]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对V10和V14执行同样的操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组</span></span><br><span class="line">v14_fraud = new_df[<span class="string">"V14"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>]</span><br><span class="line">q1, q3 = v14_fraud.quantile(<span class="number">0.25</span>), v14_fraud.quantile(<span class="number">0.75</span>)</span><br><span class="line">iqr = q3 - q1</span><br><span class="line"></span><br><span class="line">v14_cut_off = iqr * <span class="number">1.5</span></span><br><span class="line">v14_lower = q1 - v14_cut_off</span><br><span class="line">v14_upper = q3 + v14_cut_off</span><br><span class="line"></span><br><span class="line">outliers = [x <span class="keyword">for</span> x <span class="keyword">in</span> v14_fraud <span class="keyword">if</span> x &lt; v14_lower <span class="keyword">or</span> x &gt; v14_upper]</span><br><span class="line"></span><br><span class="line">new_df = new_df.drop(new_df[(new_df[<span class="string">"V14"</span>] &gt; v14_upper) | (new_df[<span class="string">"V14"</span>] &lt; v14_lower)].index)</span><br></pre></td></tr></table></figure>
<p>In [40]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对V10和V14执行同样的操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组</span></span><br><span class="line">v10_fraud = new_df[<span class="string">"V10"</span>].loc[new_df[<span class="string">"Class"</span>] == <span class="number">1</span>]</span><br><span class="line">q1, q3 = v10_fraud.quantile(<span class="number">0.25</span>), v10_fraud.quantile(<span class="number">0.75</span>)</span><br><span class="line">iqr = q3 - q1</span><br><span class="line"></span><br><span class="line">v10_cut_off = iqr * <span class="number">1.5</span></span><br><span class="line">v10_lower = q1 - v10_cut_off</span><br><span class="line">v10_upper = q3 + v10_cut_off</span><br><span class="line"></span><br><span class="line">outliers = [x <span class="keyword">for</span> x <span class="keyword">in</span> v10_fraud <span class="keyword">if</span> x &lt; v10_lower <span class="keyword">or</span> x &gt; v10_upper]</span><br><span class="line"></span><br><span class="line">new_df = new_df.drop(new_df[(new_df[<span class="string">"V10"</span>] &gt; v10_upper) | (new_df[<span class="string">"V10"</span>] &lt; v10_lower)].index)</span><br></pre></td></tr></table></figure>
<p>查看删除了异常点后的数据：</p>
<p>In [42]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2, ax3) = plt.subplots(<span class="number">1</span>,<span class="number">3</span>,figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">'#B3F9C5'</span>, <span class="string">'#f9c5b3'</span>]</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>,  <span class="comment"># 分类字段</span></span><br><span class="line">            y=<span class="string">"V14"</span>,   <span class="comment"># y轴的取值</span></span><br><span class="line">            data=new_df,  <span class="comment"># 数据框</span></span><br><span class="line">            ax=ax1,  <span class="comment"># 子图</span></span><br><span class="line">            palette=colors)</span><br><span class="line">ax1.set_title(<span class="string">"V14"</span>, fontsize=<span class="number">14</span>)  <span class="comment"># 标题</span></span><br><span class="line">ax1.annotate(<span class="string">"Fewer extreme"</span>,   <span class="comment"># 注解</span></span><br><span class="line">             xy=(<span class="number">0.98</span>,<span class="number">-17.5</span>),</span><br><span class="line">             xytext=(<span class="number">0</span>,<span class="number">-12</span>),</span><br><span class="line">             arrowprops=dict(facecolor=<span class="string">"black"</span>),</span><br><span class="line">             fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>, y=<span class="string">"V12"</span>, data=new_df, ax=ax2, palette=colors)</span><br><span class="line">ax2.set_title(<span class="string">"V12"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax2.annotate(<span class="string">"Fewer extreme"</span>,</span><br><span class="line">             xy=(<span class="number">0.98</span>,<span class="number">-17</span>),</span><br><span class="line">             xytext=(<span class="number">0</span>,<span class="number">-12</span>),</span><br><span class="line">             arrowprops=dict(facecolor=<span class="string">"black"</span>),</span><br><span class="line">             fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">sns.boxplot(x=<span class="string">"Class"</span>, y=<span class="string">"V10"</span>, data=new_df, ax=ax3, palette=colors)</span><br><span class="line">ax3.set_title(<span class="string">"V10"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax3.annotate(<span class="string">"Fewer extreme"</span>,   <span class="comment"># 注释名称</span></span><br><span class="line">             xy=(<span class="number">0.98</span>,<span class="number">-16.5</span>), <span class="comment"># 位置</span></span><br><span class="line">             xytext=(<span class="number">0</span>,<span class="number">-12</span>),  <span class="comment"># 注释文本的坐标点，二维元组，默认xy</span></span><br><span class="line">             arrowprops=dict(facecolor=<span class="string">"black"</span>), <span class="comment"># 箭头颜色</span></span><br><span class="line">             fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7u54v5ej20wc0gp750.jpg" alt=""></p>
<h2 id="降维和聚类">降维和聚类</h2>
<h3 id="理解t-SNE">理解t-SNE</h3>
<p>详细地址：<a href="https://www.youtube.com/watch?v=NEaUSP4YerM" target="_blank" rel="noopener">https://www.youtube.com/watch?v=NEaUSP4YerM</a></p>
<h3 id="欠采样数据降维">欠采样数据降维</h3>
<p>对3种不同方法实施欠采样：</p>
<p>In [43]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X = new_df.drop(<span class="string">"Class"</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = new_df[<span class="string">"Class"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># t-SNE降维</span></span><br><span class="line">t0 = time.time()</span><br><span class="line">X_reduced_tsne = TSNE(n_components=<span class="number">2</span>,</span><br><span class="line">                      random_state=<span class="number">42</span>).fit_transform(X.values)</span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">"T-SNE: "</span>, (t1 - t0))</span><br><span class="line">T-SNE:  <span class="number">5.750015020370483</span></span><br></pre></td></tr></table></figure>
<p>In [44]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA降维</span></span><br><span class="line">t0 = time.time()</span><br><span class="line">X_reduced_pca = PCA(n_components=<span class="number">2</span>,</span><br><span class="line">                    random_state=<span class="number">42</span>).fit_transform(X.values)</span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">"PCA: "</span>, (t1 - t0))</span><br><span class="line">PCA:  <span class="number">0.02214193344116211</span></span><br></pre></td></tr></table></figure>
<p>In [45]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TruncatedSVD降维</span></span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">X_reduced_svd = TruncatedSVD(n_components=<span class="number">2</span>,</span><br><span class="line">                             algorithm=<span class="string">"randomized"</span>,</span><br><span class="line">                             random_state=<span class="number">42</span>).fit_transform(X.values)</span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">"TruncatedSVD: "</span>, (t1 - t0))</span><br><span class="line">TruncatedSVD:  <span class="number">0.01066279411315918</span></span><br></pre></td></tr></table></figure>
<h3 id="绘图">绘图</h3>
<p>In [46]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2, ax3) = plt.subplots(<span class="number">1</span>,<span class="number">3</span>,figsize=(<span class="number">24</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标题设置</span></span><br><span class="line">f.suptitle(<span class="string">"Clusters using Dimensionality Reduction"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">blue_patch = mpatches.Patch(color=<span class="string">"#0A0AFF"</span>, label=<span class="string">"No Fraud"</span>)</span><br><span class="line">red_patch = mpatches.Patch(color=<span class="string">"#AF0000"</span>, label=<span class="string">"Fraud"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># t-SNE</span></span><br><span class="line">ax1.scatter(X_reduced_tsne[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_tsne[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"No Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax1.scatter(X_reduced_tsne[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_tsne[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax1.set_title(<span class="string">"t-SNE"</span>, fontsize=<span class="number">14</span>)  <span class="comment"># 子图标题设置</span></span><br><span class="line">ax1.grid(<span class="literal">True</span>)   <span class="comment"># 设置网格</span></span><br><span class="line">ax1.legend(handles=[blue_patch,red_patch])  <span class="comment"># 设置图例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">ax2.scatter(X_reduced_pca[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_pca[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"No Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax2.scatter(X_reduced_pca[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_pca[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax2.set_title(<span class="string">"PCA"</span>,  fontsize=<span class="number">14</span>)  <span class="comment"># 标题设置</span></span><br><span class="line">ax2.grid(<span class="literal">True</span>)   <span class="comment"># 设置网格</span></span><br><span class="line">ax2.legend(handles=[blue_patch,red_patch])</span><br><span class="line"></span><br><span class="line"><span class="comment"># TruncatedSVD</span></span><br><span class="line">ax3.scatter(X_reduced_svd[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_svd[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"No Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax3.scatter(X_reduced_svd[:,<span class="number">0</span>],</span><br><span class="line">            X_reduced_svd[:,<span class="number">1</span>],</span><br><span class="line">            c=(y==<span class="number">0</span>),</span><br><span class="line">            cmap=<span class="string">"coolwarm"</span>,</span><br><span class="line">            label=<span class="string">"Fraud"</span>,</span><br><span class="line">            linewidths=<span class="number">2</span></span><br><span class="line">           )</span><br><span class="line">ax3.set_title(<span class="string">"TruncatedSVD"</span>, fontsize=<span class="number">14</span>)  <span class="comment"># 标题设置</span></span><br><span class="line">ax3.grid(<span class="literal">True</span>)   <span class="comment"># 设置网格</span></span><br><span class="line">ax3.legend(handles=[blue_patch,red_patch])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7v3za2ij21270b2dhm.jpg" alt=""></p>
<h2 id="基于欠采样的分类建模">基于欠采样的分类建模</h2>
<h3 id="4个分类模型">4个分类模型</h3>
<p>采用4个不同模型的分类来训练数据，看哪个模型在欺诈数据上表现的更好。首先需要对数据进行划分：训练集和测试集</p>
<p>In [47]:</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 1、特征和标签数据</span></span><br><span class="line"></span><br><span class="line">X = <span class="keyword">new</span><span class="type">_df</span>.drop(<span class="string">"Class"</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = <span class="keyword">new</span><span class="type">_df</span>[<span class="string">"Class"</span>]</span><br></pre></td></tr></table></figure>
<p>In [48]:</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2</span>、数据已经归一化，直接切分</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"># <span class="number">8</span><span class="number">-2</span>的比例</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">44</span>)</span><br></pre></td></tr></table></figure>
<p>In [49]:</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3、将数据转成数组，然后传给模型</span></span><br><span class="line"><span class="attr">X_train</span> = X_train.values</span><br><span class="line"><span class="attr">X_test</span> = X_test.values</span><br><span class="line"></span><br><span class="line"><span class="attr">y_train</span> = y_train.values</span><br><span class="line"><span class="attr">y_test</span> = y_test.values</span><br></pre></td></tr></table></figure>
<p>In [50]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4、创建4个模型</span></span><br><span class="line">classifiers = &#123;</span><br><span class="line">    <span class="string">"逻辑回归LogisiticRegression"</span>: LogisticRegression(),</span><br><span class="line">    <span class="string">"K近邻KNearest"</span>: KNeighborsClassifier(),</span><br><span class="line">    <span class="string">"支持向量机分类Support Vector Classifier"</span>: SVC(),</span><br><span class="line">    <span class="string">"决策树分类DecisionTreeClassifier"</span>: DecisionTreeClassifier()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key, classifier <span class="keyword">in</span> classifiers.items():</span><br><span class="line">    classifier.fit(X_train, y_train)  <span class="comment"># 模型训练</span></span><br><span class="line">    training_score = cross_val_score(classifier, <span class="comment"># 模型</span></span><br><span class="line">                                     X_train,   <span class="comment"># 训练集数据</span></span><br><span class="line">                                     y_train,</span><br><span class="line">                                     cv=<span class="number">5</span>)  <span class="comment"># 5折交叉验证</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"模型-"</span>, key,</span><br><span class="line">      <span class="string">"5次平均得分："</span>, round(training_score.mean(), <span class="number">2</span>)*<span class="number">100</span>)</span><br><span class="line">模型- 逻辑回归LogisiticRegression <span class="number">5</span>次平均得分： <span class="number">93.0</span></span><br><span class="line">模型- K近邻KNearest <span class="number">5</span>次平均得分： <span class="number">93.0</span></span><br><span class="line">模型- 支持向量机分类Support Vector Classifier <span class="number">5</span>次平均得分： <span class="number">93.0</span></span><br><span class="line">模型- 决策树分类DecisionTreeClassifier <span class="number">5</span>次平均得分： <span class="number">91.0</span></span><br></pre></td></tr></table></figure>
<h3 id="网格搜索">网格搜索</h3>
<p>针对不同测模型实施网格搜索，寻找最优参数</p>
<p>In [51]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归</span></span><br><span class="line">lr_params = &#123;<span class="string">"penalty"</span>:[<span class="string">"l1"</span>, <span class="string">"l2"</span>],</span><br><span class="line">             <span class="string">"C"</span>: [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line">            &#125;</span><br><span class="line">grid_lr = GridSearchCV(LogisticRegression(), lr_params)</span><br><span class="line">grid_lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最好的参数组合</span></span><br><span class="line">best_para_lr = grid_lr.best_estimator_</span><br><span class="line">best_para_lr</span><br></pre></td></tr></table></figure>
<p>Out[51]:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">LogisticRegression</span><span class="params">(C=<span class="number">0.1</span>)</span></span></span><br></pre></td></tr></table></figure>
<p>In [52]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k近邻</span></span><br><span class="line">knn_params = &#123;<span class="string">"n_neighbors"</span>: list(range(<span class="number">2</span>,<span class="number">5</span>,<span class="number">1</span>)),</span><br><span class="line">              <span class="string">"algorithm"</span>:[<span class="string">"auto"</span>,<span class="string">"ball_tree"</span>,<span class="string">"kd_tree"</span>,<span class="string">"brute"</span>]</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">grid_knn = GridSearchCV(KNeighborsClassifier(), knn_params)</span><br><span class="line">grid_knn.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最好的参数组合</span></span><br><span class="line">best_para_knn = grid_knn.best_estimator_</span><br><span class="line">best_para_knn</span><br></pre></td></tr></table></figure>
<p>Out[52]:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">KNeighborsClassifier</span><span class="params">(n_neighbors=<span class="number">2</span>)</span></span></span><br></pre></td></tr></table></figure>
<p>In [53]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 支持向量机分类</span></span><br><span class="line"></span><br><span class="line">svc_params = &#123;<span class="string">"C"</span>:[<span class="number">0.5</span>, <span class="number">0.7</span>, <span class="number">0.9</span>, <span class="number">1</span>],</span><br><span class="line">              <span class="string">"kernel"</span>:[<span class="string">"rbf"</span>,<span class="string">"poly"</span>,<span class="string">"sigmoid"</span>,<span class="string">"linear"</span>]</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">grid_svc = GridSearchCV(SVC(), svc_params)</span><br><span class="line">grid_svc.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">best_para_svc = grid_svc.best_estimator_</span><br><span class="line">best_para_svc</span><br></pre></td></tr></table></figure>
<p>Out[53]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SVC(<span class="attribute">C</span>=0.9, <span class="attribute">kernel</span>=<span class="string">'linear'</span>)</span><br></pre></td></tr></table></figure>
<p>In [54]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 决策树</span></span><br><span class="line"></span><br><span class="line">dt_params = &#123;<span class="string">"criterion"</span>:[<span class="string">"gini"</span>,<span class="string">"entropy"</span>],</span><br><span class="line">             <span class="string">"max_depth"</span>:list(range(<span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>)),</span><br><span class="line">             <span class="string">"min_samples_leaf"</span>: list(range(<span class="number">5</span>,<span class="number">7</span>,<span class="number">1</span>))</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">grid_dt = GridSearchCV(DecisionTreeClassifier(), dt_params)</span><br><span class="line">grid_dt.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">best_para_dt = grid_dt.best_estimator_</span><br><span class="line">best_para_dt</span><br></pre></td></tr></table></figure>
<p>Out[54]:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DecisionTreeClassifier(<span class="attribute">max_depth</span>=3, <span class="attribute">min_samples_leaf</span>=5)</span><br></pre></td></tr></table></figure>
<h3 id="重新训练并评分">重新训练并评分</h3>
<p>基于最优参数重新计算得分：</p>
<p>In [55]:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr_score = cross_val_score(best_para_lr, X_train, y_train,cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"逻辑回归交叉验证得分："</span>, round(lr_score.mean() * <span class="number">100</span>, <span class="number">2</span>).astype(str) + <span class="string">"%"</span>)</span><br><span class="line">逻辑回归交叉验证得分： <span class="number">93.63</span>%</span><br></pre></td></tr></table></figure>
<p>In [56]:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">knn_score = cross_val_score(best_para_knn, X_train, y_train,cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"KNN交叉验证得分："</span>, round(knn_score.mean() * <span class="number">100</span>, <span class="number">2</span>).astype(str) + <span class="string">"%"</span>)</span><br><span class="line">KNN交叉验证得分： <span class="number">93.37</span>%</span><br></pre></td></tr></table></figure>
<p>In [57]:</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">svc_score </span>= cross_val_score(<span class="keyword">best_para_svc, </span>X_train, y_train,cv<span class="number">=5</span>)</span><br><span class="line"></span><br><span class="line"><span class="symbol">print</span>(<span class="string">"SVC交叉验证得分："</span>, round(<span class="keyword">svc_score.mean() </span>* <span class="number">100</span>, <span class="number">2</span>).astype(<span class="keyword">str) </span>+ <span class="string">"%"</span>)</span><br><span class="line"><span class="keyword">SVC交叉验证得分： </span><span class="number">93</span>.<span class="number">5</span>%</span><br></pre></td></tr></table></figure>
<p>In [58]:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_score = cross_val_score(best_para_dt, X_train, y_train,cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"决策树交叉验证得分："</span>, round(dt_score.mean() * <span class="number">100</span>, <span class="number">2</span>).astype(str) + <span class="string">"%"</span>)</span><br><span class="line">决策树交叉验证得分： <span class="number">93.24</span>%</span><br></pre></td></tr></table></figure>
<p>小结：通过不同模型的交叉验证得分我们发现，逻辑回归模型是最高的</p>
<h2 id="基于欠采样数据的交叉验证">基于欠采样数据的交叉验证</h2>
<p>主要是基于Near-Miss算法来实现欠采样：</p>
<ul>
<li>Near-miss-1：选择到最近的三个样本平均距离最小的多数类样本</li>
<li>Near-miss-2：选择到最远的三个样本平均距离最小的多数类样本</li>
<li>Near-miss-3：为每个少数类样本选择给定数目的最近多数类样本</li>
<li>最远距离：选择到最近的三个样本平均距离最大的多样类样本</li>
</ul>
<p>In [59]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">undersample_X = df.drop(<span class="string">"Class"</span>, axis=<span class="number">1</span>)</span><br><span class="line">undersample_y = df[<span class="string">"Class"</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sfk = StratifiedKFold(</span><br><span class="line">    n_splits=<span class="number">5</span>,   <span class="comment"># 5次交叉验证</span></span><br><span class="line">    random_state=<span class="literal">None</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index , test_index <span class="keyword">in</span> sfk.split(undersample_X,undersample_y):</span><br><span class="line">  	<span class="comment"># 每次随机生成的验证集和测试集的索引号</span></span><br><span class="line">    <span class="comment"># print("Train: ", train_index)</span></span><br><span class="line">    <span class="comment"># print("Test: ", test_index)</span></span><br><span class="line"></span><br><span class="line">    undersample_Xtrain = undersample_X.iloc[train_index]  <span class="comment"># 根据索引号来确定数据</span></span><br><span class="line">    undersample_Xtest = undersample_X.iloc[test_index]</span><br><span class="line"></span><br><span class="line">    undersample_ytrain = undersample_y.iloc[train_index]</span><br><span class="line">    undersample_ytest = undersample_y.iloc[test_index]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据转成numpy数组</span></span><br><span class="line">undersample_Xtrain = undersample_Xtrain.values</span><br><span class="line">undersample_Xtest = undersample_Xtest.values</span><br><span class="line">undersample_ytrain = undersample_ytrain.values</span><br><span class="line">undersample_ytest = undersample_ytest.values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5个评价指标</span></span><br><span class="line">undersample_accuracy = []</span><br><span class="line">undersample_precision = []</span><br><span class="line">undersample_recall = []</span><br><span class="line">undersample_f1 = []</span><br><span class="line">undersample_auc = []</span><br></pre></td></tr></table></figure>
<p>使用近邻缺失Near-Miss算法来查看数据分布：</p>
<p>In [60]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">undersample_X = df.drop(<span class="string">"Class"</span>, axis=<span class="number">1</span>)</span><br><span class="line">undersample_y = df[<span class="string">"Class"</span>]</span><br><span class="line"></span><br><span class="line">X_nearmiss, y_nearmiss = NearMiss().fit_resample(undersample_X.values, undersample_y.values)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"NearMiss Label Distributions: &#123;&#125;"</span>, format(Counter(y_nearmiss)))</span><br><span class="line">NearMiss Label Distributions: &#123;&#125; Counter(&#123;<span class="number">0</span>: <span class="number">492</span>, <span class="number">1</span>: <span class="number">492</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>以<strong>网格搜索过后的逻辑回归模型</strong>来实施交叉验证：</p>
<p>In [61]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> sfk.split(undersample_Xtrain, undersample_ytrain):</span><br><span class="line">    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy=<span class="string">"majority"</span>), best_para_lr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型训练：传入训练X-y</span></span><br><span class="line">    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对测试集预测-Xtrain</span></span><br><span class="line">    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># y_test真实值和预测值的评分</span></span><br><span class="line">    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))</span><br><span class="line">    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))</span><br><span class="line">    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))</span><br><span class="line">    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))</span><br><span class="line">    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))</span><br></pre></td></tr></table></figure>
<h2 id="绘制学习曲线">绘制学习曲线</h2>
<p>In [62]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit, learning_curve</span><br></pre></td></tr></table></figure>
<p>In [63]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span><span class="params">(est1,est2,est3,est4,X,y,ylim=None,cv=None,n_jobs=<span class="number">1</span>,train_sizes=np.linspace<span class="params">(<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">5</span>)</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">    f, ((ax1,ax2), (ax3,ax4)) = plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">14</span>), sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.ylim(*ylim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型1</span></span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(</span><br><span class="line">        est1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)  <span class="comment"># 训练集的均值和方差</span></span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)   <span class="comment"># 测试集的均值和方差</span></span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,  <span class="comment"># 填充区域的设置</span></span><br><span class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">"#ff9124"</span>)</span><br><span class="line">    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">"#2492ff"</span>)</span><br><span class="line">    ax1.plot(train_sizes, train_scores_mean,</span><br><span class="line">             <span class="string">'o-'</span>, color=<span class="string">"#ff9124"</span>,</span><br><span class="line">             label=<span class="string">"Training score"</span>)  <span class="comment"># 绘制训练集得分</span></span><br><span class="line">    ax1.plot(train_sizes, test_scores_mean,</span><br><span class="line">             <span class="string">'o-'</span>, color=<span class="string">"#2492ff"</span>,</span><br><span class="line">             label=<span class="string">"Cross-validation score"</span>)  <span class="comment"># 绘制交叉验证得分</span></span><br><span class="line">    ax1.set_title(<span class="string">"逻辑回归学习曲线"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    ax1.set_xlabel(<span class="string">'Training size (m)'</span>)  <span class="comment"># 两个轴的标题</span></span><br><span class="line">    ax1.set_ylabel(<span class="string">'Score'</span>)</span><br><span class="line">    ax1.grid(<span class="literal">True</span>)  <span class="comment"># 网格显示</span></span><br><span class="line">    ax1.legend(loc=<span class="string">"best"</span>)  <span class="comment"># 图例位置</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型2-knn</span></span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(</span><br><span class="line">        est2, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">"#ff9124"</span>)</span><br><span class="line">    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">"#2492ff"</span>)</span><br><span class="line">    ax2.plot(train_sizes, train_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#ff9124"</span>,</span><br><span class="line">             label=<span class="string">"Training score"</span>)</span><br><span class="line">    ax2.plot(train_sizes, test_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#2492ff"</span>,</span><br><span class="line">             label=<span class="string">"Cross-validation score"</span>)</span><br><span class="line">    ax2.set_title(<span class="string">"k近邻学习曲线"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    ax2.set_xlabel(<span class="string">'Training size (m)'</span>)</span><br><span class="line">    ax2.set_ylabel(<span class="string">'Score'</span>)</span><br><span class="line">    ax2.grid(<span class="literal">True</span>)</span><br><span class="line">    ax2.legend(loc=<span class="string">"best"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型3-支持向量机</span></span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(</span><br><span class="line">        est3, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">"#ff9124"</span>)</span><br><span class="line">    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">"#2492ff"</span>)</span><br><span class="line">    ax3.plot(train_sizes, train_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#ff9124"</span>,</span><br><span class="line">             label=<span class="string">"Training score"</span>)</span><br><span class="line">    ax3.plot(train_sizes, test_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#2492ff"</span>,</span><br><span class="line">             label=<span class="string">"Cross-validation score"</span>)</span><br><span class="line">    ax3.set_title(<span class="string">"支持向量机学习曲线"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    ax3.set_xlabel(<span class="string">'Training size (m)'</span>)</span><br><span class="line">    ax3.set_ylabel(<span class="string">'Score'</span>)</span><br><span class="line">    ax3.grid(<span class="literal">True</span>)</span><br><span class="line">    ax3.legend(loc=<span class="string">"best"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型4-决策树</span></span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(</span><br><span class="line">        est4, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">"#ff9124"</span>)</span><br><span class="line">    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">"#2492ff"</span>)</span><br><span class="line">    ax4.plot(train_sizes, train_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#ff9124"</span>,</span><br><span class="line">             label=<span class="string">"Training score"</span>)</span><br><span class="line">    ax4.plot(train_sizes, test_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"#2492ff"</span>,</span><br><span class="line">             label=<span class="string">"Cross-validation score"</span>)</span><br><span class="line">    ax4.set_title(<span class="string">"决策树学习曲线"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    ax4.set_xlabel(<span class="string">'Training size (m)'</span>)</span><br><span class="line">    ax4.set_ylabel(<span class="string">'Score'</span>)</span><br><span class="line">    ax4.grid(<span class="literal">True</span>)</span><br><span class="line">    ax4.legend(loc=<span class="string">"best"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> plt</span><br></pre></td></tr></table></figure>
<p>In [64]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cv = ShuffleSplit(n_splits=<span class="number">100</span>,</span><br><span class="line">                  test_size=<span class="number">0.2</span>,</span><br><span class="line">                  random_state=<span class="number">42</span></span><br><span class="line">                 )</span><br><span class="line"></span><br><span class="line">plot_learning_curve(best_para_lr,  <span class="comment"># 传入4种模型</span></span><br><span class="line">                    best_para_knn,</span><br><span class="line">                    best_para_svc,</span><br><span class="line">                    best_para_dt,</span><br><span class="line">                    X_train,</span><br><span class="line">                    y_train,</span><br><span class="line">                    (<span class="number">0.87</span>,<span class="number">1.01</span>),</span><br><span class="line">                    cv=cv,</span><br><span class="line">                    n_jobs=<span class="number">4</span></span><br><span class="line">                   )</span><br><span class="line"></span><br><span class="line">plt.show</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7y6ll57j20wh0mt40s.jpg" alt=""></p>
<h2 id="roc曲线">roc曲线</h2>
<p>In [65]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br></pre></td></tr></table></figure>
<p>In [66]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">lr_pred = cross_val_predict(best_para_lr,</span><br><span class="line">                            X_train,</span><br><span class="line">                            y_train,</span><br><span class="line">                            cv=<span class="number">5</span>,</span><br><span class="line">                            <span class="comment"># method="decision_function"</span></span><br><span class="line">                           )</span><br><span class="line"></span><br><span class="line">knn_pred = cross_val_predict(best_para_knn,</span><br><span class="line">                            X_train,</span><br><span class="line">                            y_train,</span><br><span class="line">                            cv=<span class="number">5</span></span><br><span class="line">                           )</span><br><span class="line"></span><br><span class="line">svc_pred = cross_val_predict(best_para_svc,</span><br><span class="line">                            X_train,</span><br><span class="line">                            y_train,</span><br><span class="line">                            cv=<span class="number">5</span></span><br><span class="line">                           )</span><br><span class="line">dt_pred = cross_val_predict(best_para_dt,</span><br><span class="line">                            X_train,</span><br><span class="line">                            y_train,</span><br><span class="line">                            cv=<span class="number">5</span></span><br><span class="line">                           )</span><br></pre></td></tr></table></figure>
<p>In [67]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Logistic Regression: '</span>, roc_auc_score(y_train, lr_pred))</span><br><span class="line">print(<span class="string">'KNears Neighbors: '</span>, roc_auc_score(y_train, knn_pred))</span><br><span class="line">print(<span class="string">'Support Vector Classifier: '</span>, roc_auc_score(y_train, svc_pred))</span><br><span class="line">print(<span class="string">'Decision Tree Classifier: '</span>, roc_auc_score(y_train, dt_pred))</span><br><span class="line"></span><br><span class="line">Logistic Regression:  <span class="number">0.934970120644943</span></span><br><span class="line">KNears Neighbors:  <span class="number">0.9314677528469951</span></span><br><span class="line">Support Vector Classifier:  <span class="number">0.9339060209719247</span></span><br><span class="line">Decision Tree Classifier:  <span class="number">0.930932179501635</span></span><br></pre></td></tr></table></figure>
<p>In [68]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">log_fpr, log_tpr, log_thresold = roc_curve(y_train, lr_pred)</span><br><span class="line">knear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knn_pred)</span><br><span class="line">svc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)</span><br><span class="line">tree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, dt_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制tpr-fpr得分图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">graph_roc_curve_multiple</span><span class="params">(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">    plt.title(<span class="string">'ROC Curve \n Top 4 Classifiers'</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">    plt.plot(log_fpr, log_tpr, label=<span class="string">'Logistic Regression Classifier Score: &#123;:.4f&#125;'</span>.format(roc_auc_score(y_train, lr_pred)))</span><br><span class="line">    plt.plot(knear_fpr, knear_tpr, label=<span class="string">'KNears Neighbors Classifier Score: &#123;:.4f&#125;'</span>.format(roc_auc_score(y_train, knn_pred)))</span><br><span class="line">    plt.plot(svc_fpr, svc_tpr, label=<span class="string">'Support Vector Classifier Score: &#123;:.4f&#125;'</span>.format(roc_auc_score(y_train, svc_pred)))</span><br><span class="line">    plt.plot(tree_fpr, tree_tpr, label=<span class="string">'Decision Tree Classifier Score: &#123;:.4f&#125;'</span>.format(roc_auc_score(y_train, dt_pred)))</span><br><span class="line"></span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'k--'</span>)</span><br><span class="line">    plt.axis([<span class="number">-0.01</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.annotate(<span class="string">'Minimum ROC Score of 50% \n (This is the minimum score to get)'</span>,</span><br><span class="line">                 xy=(<span class="number">0.5</span>, <span class="number">0.5</span>),</span><br><span class="line">                 xytext=(<span class="number">0.6</span>, <span class="number">0.3</span>),</span><br><span class="line">                arrowprops=dict(facecolor=<span class="string">'#6E726D'</span>, shrink=<span class="number">0.05</span>),</span><br><span class="line">                )</span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1t7zves02j20qi0ecq3r.jpg" alt=""></p>
<h2 id="探索逻辑回归评价指标">探索逻辑回归评价指标</h2>
<p>探索在逻辑回归模型的分类评价指标：</p>
<p>In [69]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_roc_curve</span><span class="params">(log_fpr, log_tpr)</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">    plt.title(<span class="string">'Logistic Regression ROC Curve'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.plot(log_fpr, log_tpr, <span class="string">'b-'</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'r--'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.axis([<span class="number">-0.01</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logistic_roc_curve(log_fpr, log_tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1tsbo0bpjj20kb0dwmxk.jpg" alt=""></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"></span><br><span class="line"><span class="type">precision</span>, recall, threshold = precision_recall_curve(y_train, lr_pred)</span><br></pre></td></tr></table></figure>
<p>In [71]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score, precision_score, f1_score, accuracy_score</span><br><span class="line">y_pred = best_para_lr.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Overfitting Case</span></span><br><span class="line">print(<span class="string">'---'</span> * <span class="number">20</span>)</span><br><span class="line">print(<span class="string">'Recall Score: &#123;:.2f&#125;'</span>.format(recall_score(y_train, y_pred)))</span><br><span class="line">print(<span class="string">'Precision Score: &#123;:.2f&#125;'</span>.format(precision_score(y_train, y_pred)))</span><br><span class="line">print(<span class="string">'F1 Score: &#123;:.2f&#125;'</span>.format(f1_score(y_train, y_pred)))</span><br><span class="line">print(<span class="string">'Accuracy Score: &#123;:.2f&#125;'</span>.format(accuracy_score(y_train, y_pred)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'---'</span> * <span class="number">20</span>)</span><br><span class="line">print(<span class="string">"Accuracy Score: &#123;:.2f&#125;"</span>.format(np.mean(undersample_accuracy)))</span><br><span class="line">print(<span class="string">"Precision Score: &#123;:.2f&#125;"</span>.format(np.mean(undersample_precision)))</span><br><span class="line">print(<span class="string">"Recall Score: &#123;:.2f&#125;"</span>.format(np.mean(undersample_recall)))</span><br><span class="line">print(<span class="string">"F1 Score: &#123;:.2f&#125;"</span>.format(np.mean(undersample_f1)))</span><br><span class="line">print(<span class="string">'---'</span> * <span class="number">20</span>)</span><br><span class="line">------------------------------------------------------------</span><br><span class="line"><span class="comment"># 基于原数据</span></span><br><span class="line">Recall Score: <span class="number">0.92</span></span><br><span class="line">Precision Score: <span class="number">0.79</span></span><br><span class="line">F1 Score: <span class="number">0.85</span></span><br><span class="line">Accuracy Score: <span class="number">0.84</span></span><br><span class="line"></span><br><span class="line">------------------------------------------------------------</span><br><span class="line"> <span class="comment"># 基于欠采样的数据</span></span><br><span class="line">Accuracy Score: <span class="number">0.75</span></span><br><span class="line">Precision Score: <span class="number">0.00</span></span><br><span class="line">Recall Score: <span class="number">0.24</span></span><br><span class="line">F1 Score: <span class="number">0.00</span></span><br><span class="line">------------------------------------------------------------</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

<div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html">极不均衡样本的信用卡欺诈分析</a></p>
  <p><span>发布时间:</span>2022年05月02日 - 09:05</p>
  <p><span>原始链接:</span><a href="/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html" title="极不均衡样本的信用卡欺诈分析">http://www.renpeter.cn/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://www.renpeter.cn/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html"  aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
	  $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
	    });
    });  
</script>

      
</div>


    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Coffee or Tea</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="PiQianChao WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
            <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag"># 逻辑回归</a>
          
            <a href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/" rel="tag"># 异常检测</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/04/28/Docker%E4%BB%8E%E6%94%BE%E5%BC%83%E5%88%B0%E5%85%A5%E9%97%A8.html" rel="next" title="Docker从放弃到入门">
                <i class="fa fa-chevron-left"></i> Docker从放弃到入门
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/05/06/LaTex%E7%AC%A6%E5%8F%B7%E5%A4%87%E5%BF%98%E5%BD%95.html" rel="prev" title="LaTex符号备忘录">
                LaTex符号备忘录 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/cunshang.jpg"
                alt="PiQianChao" />
            
              <p class="site-author-name" itemprop="name">PiQianChao</p>
              <p class="site-description motion-element" itemprop="description">My Blog</p>
          </div>
            
           <iframe  frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=694660&auto=1&height=66"></iframe>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">745</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">99</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">110</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/pidada" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:pichaochao1119@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#非均衡样本下的信用卡欺诈分析"><span class="nav-number">1.</span> <span class="nav-text">非均衡样本下的信用卡欺诈分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#导入库"><span class="nav-number">2.</span> <span class="nav-text">导入库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本信息"><span class="nav-number">3.</span> <span class="nav-text">基本信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正负样本不均衡"><span class="nav-number">4.</span> <span class="nav-text">正负样本不均衡</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查看特征分布"><span class="nav-number">5.</span> <span class="nav-text">查看特征分布</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#直方图分布"><span class="nav-number">5.1.</span> <span class="nav-text">直方图分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征分布箱型图"><span class="nav-number">5.2.</span> <span class="nav-text">特征分布箱型图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据预处理"><span class="nav-number">6.</span> <span class="nav-text">数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据缩放和分布"><span class="nav-number">6.1.</span> <span class="nav-text">数据缩放和分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧1：新字段位置"><span class="nav-number">6.2.</span> <span class="nav-text">技巧1：新字段位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分割数据（基于原DataFrame）"><span class="nav-number">6.3.</span> <span class="nav-text">分割数据（基于原DataFrame）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧2：生成随机索引"><span class="nav-number">6.4.</span> <span class="nav-text">技巧2：生成随机索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧3：数据唯一值及比例"><span class="nav-number">6.5.</span> <span class="nav-text">技巧3：数据唯一值及比例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#欠采样"><span class="nav-number">7.</span> <span class="nav-text">欠采样</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原理"><span class="nav-number">7.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤"><span class="nav-number">7.2.</span> <span class="nav-text">步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺点"><span class="nav-number">7.3.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实施采样"><span class="nav-number">7.4.</span> <span class="nav-text">实施采样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#均匀分布"><span class="nav-number">7.5.</span> <span class="nav-text">均匀分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关性分析"><span class="nav-number">8.</span> <span class="nav-text">相关性分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#系数矩阵热力图"><span class="nav-number">8.1.</span> <span class="nav-text">系数矩阵热力图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#箱型图"><span class="nav-number">8.2.</span> <span class="nav-text">箱型图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#异常检测"><span class="nav-number">9.</span> <span class="nav-text">异常检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目的"><span class="nav-number">9.1.</span> <span class="nav-text">目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方法"><span class="nav-number">9.2.</span> <span class="nav-text">方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#异常值去除权衡"><span class="nav-number">9.3.</span> <span class="nav-text">异常值去除权衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征分布-直方图"><span class="nav-number">9.4.</span> <span class="nav-text">特征分布-直方图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧4：删除离群点"><span class="nav-number">9.5.</span> <span class="nav-text">技巧4：删除离群点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#降维和聚类"><span class="nav-number">10.</span> <span class="nav-text">降维和聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#理解t-SNE"><span class="nav-number">10.1.</span> <span class="nav-text">理解t-SNE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#欠采样数据降维"><span class="nav-number">10.2.</span> <span class="nav-text">欠采样数据降维</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#绘图"><span class="nav-number">10.3.</span> <span class="nav-text">绘图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于欠采样的分类建模"><span class="nav-number">11.</span> <span class="nav-text">基于欠采样的分类建模</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4个分类模型"><span class="nav-number">11.1.</span> <span class="nav-text">4个分类模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网格搜索"><span class="nav-number">11.2.</span> <span class="nav-text">网格搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#重新训练并评分"><span class="nav-number">11.3.</span> <span class="nav-text">重新训练并评分</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于欠采样数据的交叉验证"><span class="nav-number">12.</span> <span class="nav-text">基于欠采样数据的交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#绘制学习曲线"><span class="nav-number">13.</span> <span class="nav-text">绘制学习曲线</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#roc曲线"><span class="nav-number">14.</span> <span class="nav-text">roc曲线</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#探索逻辑回归评价指标"><span class="nav-number">15.</span> <span class="nav-text">探索逻辑回归评价指标</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

	
	
		<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
		<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
		<div class="widget-wrap">
			<h3 class="widget-title">标签云</h3>
			<div id="myCanvasContainer" class="widget tagcloud">
			<canvas width="250" height="250" id="resCanvas" style="width=100%">
				 <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSV/" rel="tag">CSV</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JJ/" rel="tag">JJ</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kats/" rel="tag">Kats</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/" rel="tag">Keras</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LaTex/" rel="tag">LaTex</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LeetCode/" rel="tag">LeetCode</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Leetcode/" rel="tag">Leetcode</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/" rel="tag">MySQL</a><span class="tag-list-count">63</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCA/" rel="tag">PCA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/d3/" rel="tag">d3</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dash/" rel="tag">dash</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/" rel="tag">go</a><span class="tag-list-count">42</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/highcharts/" rel="tag">highcharts</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/json/" rel="tag">json</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kaggle/" rel="tag">kaggle</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/keras/" rel="tag">keras</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a><span class="tag-list-count">134</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plotly/" rel="tag">plotly</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/px/" rel="tag">px</a><span class="tag-list-count">35</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyecharts/" rel="tag">pyecharts</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyg2plot/" rel="tag">pyg2plot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">94</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seaborn/" rel="tag">seaborn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/" rel="tag">spider</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sql/" rel="tag">sql</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlzoo/" rel="tag">sqlzoo</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tableau/" rel="tag">tableau</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/uci/" rel="tag">uci</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%92%E8%81%94%E7%BD%91/" rel="tag">互联网</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%A7%E5%93%81/" rel="tag">产品</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/" rel="tag">关联分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99/" rel="tag">关联规则</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C/" rel="tag">写作</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%B1%BB/" rel="tag">分类</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8C%BA%E5%9F%9F%E9%93%BE/" rel="tag">区域链</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%B7%E7%A7%AF/" rel="tag">卷积</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AC%E5%9B%9E%E7%8E%87/" rel="tag">召回率</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a><span class="tag-list-count">123</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/" rel="tag">吴恩达</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BD%92/" rel="tag">回归</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" rel="tag">回归分析</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E9%87%91/" rel="tag">基金</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a><span class="tag-list-count">48</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E5%85%B8/" rel="tag">字典</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8/" rel="tag">容器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%BC%E6%95%B0/" rel="tag">导数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%80%E6%BA%90/" rel="tag">开源</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/" rel="tag">异常检测</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AA%E7%8E%AF/" rel="tag">循环</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%88%90%E9%95%BF/" rel="tag">成长</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%95%E8%B5%84/" rel="tag">投资</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag">推荐系统</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag">数学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a><span class="tag-list-count">79</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" rel="tag">数据处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a><span class="tag-list-count">102</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag">数据挖掘</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/" rel="tag">文本处理</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%85%E6%B8%B8/" rel="tag">旅游</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3/" rel="tag">无监督</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">无监督学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" rel="tag">时序分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" rel="tag">时间序列</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">113</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AD%A3%E5%88%99%E5%8C%96/" rel="tag">正则化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%9C%B3/" rel="tag">深圳</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">25</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E6%BC%82/" rel="tag">深漂</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="tag">激活函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%9F%E6%B4%BB/" rel="tag">生活</a><span class="tag-list-count">50</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%B5%E5%BD%B1/" rel="tag">电影</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">监督学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%AF%E5%88%86/" rel="tag">积分</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B2%BE%E5%BA%A6/" rel="tag">精度</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B4%A2%E5%BC%95/" rel="tag">索引</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E/" rel="tag">经济</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1/" rel="tag">统计</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B/" rel="tag">编程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%BA%E5%A4%B1%E5%80%BC/" rel="tag">缺失值</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BE%8E%E9%A3%9F/" rel="tag">美食</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%81%9A%E7%B1%BB/" rel="tag">聚类</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/" rel="tag">自动化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86/" rel="tag">自我管理</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/" rel="tag">计算机</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E8%90%A5/" rel="tag">运营</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag">逻辑回归</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%87%8D%E5%A4%8D%E5%80%BC/" rel="tag">重复值</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB/" rel="tag">阅读</a><span class="tag-list-count">28</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%99%8D%E7%BB%B4/" rel="tag">降维</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" rel="tag">随机森林</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" rel="tag">集成学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%92%E6%98%A5/" rel="tag">青春</a><span class="tag-list-count">1</span></li></ul>
			</canvas>
			</div>
		</div>
	

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PiQianChao</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共1114.6k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="true"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://pidada.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.renpeter.cn/2022/05/02/%E6%9E%81%E4%B8%8D%E5%9D%87%E8%A1%A1%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%AC%BA%E8%AF%88%E5%88%86%E6%9E%90.html';
          this.page.identifier = '2022/05/02/极不均衡样本的信用卡欺诈分析.html';
          this.page.title = '极不均衡样本的信用卡欺诈分析';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://pidada.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script>


  




<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


</body>
</html>
