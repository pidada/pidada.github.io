<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习,激活函数,梯度," />





  <link rel="alternate" href="/atom.xml" title="尤尔小屋" type="application/atom+xml" />






<meta name="description" content="深度学习4大激活函数 如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层输出实际上都是上层输入的线性函数。 这样就使得无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，模型的表达力仍然不够。 我们决定引入非线性函数作为激励函数，这样深层神经网络才有意义（不再是输入的线性组合）。">
<meta name="keywords" content="深度学习,激活函数,梯度">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习4大激活函数">
<meta property="og:url" content="http:&#x2F;&#x2F;www.renpeter.cn&#x2F;2022&#x2F;10&#x2F;25&#x2F;%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html">
<meta property="og:site_name" content="尤尔小屋">
<meta property="og:description" content="深度学习4大激活函数 如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层输出实际上都是上层输入的线性函数。 这样就使得无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，模型的表达力仍然不够。 我们决定引入非线性函数作为激励函数，这样深层神经网络才有意义（不再是输入的线性组合）。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbzrkldhj30vq0i441l.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbcpmyecj30ac06wq2z.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbd9ryjdj30ai06wwek.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbrp5jubj30iz0ch3ym.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbsgdkaqj30iz0cijri.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbt1ul49j30fw09gq32.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbtmuducj30jj09x0sz.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbuxi7llj30jm09xjrl.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;image.jiqizhixin.com&#x2F;uploads&#x2F;editor&#x2F;91a214e0-d773-4ede-be3b-3f046ae5e1d4&#x2F;640.png">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbvkrl3oj30jj09xjrn.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbvnj3x5j30jm09xaa9.jpg">
<meta property="og:updated_time" content="2022-10-25T03:59:59.830Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;008vxvgGly1h7hbzrkldhj30vq0i441l.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    
    emojis: {
      className: 'github-emoji'
    }
  };
</script>



  <link rel="canonical" href="http://www.renpeter.cn/2022/10/25/深度学习4大激活函数.html"/>





  <title>深度学习4大激活函数 | 尤尔小屋</title>
  








</head>


<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

   <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/pidada" target="_blank" rel="noopener"><img style="position: absolute; top: 0; right: 0; border: 0" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_white_ffffff.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">尤尔小屋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Stay Foolish Stay Hungry</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-links">
          <a href="/links/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-link"></i> <br />
            
            links
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.renpeter.cn/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PiQianChao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cunshang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="尤尔小屋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习4大激活函数</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-10-25T11:58:53+08:00">
                2022-10-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index">
                    <span itemprop="name">DL</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/%E6%A6%82%E5%BF%B5/" itemprop="url" rel="index">
                    <span itemprop="name">概念</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2022/10/25/深度学习4大激活函数.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  14
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="深度学习4大激活函数">深度学习4大激活函数</h2>
<p>如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层输出实际上都是上层输入的线性函数。</p>
<p>这样就使得无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，模型的表达力仍然不够。</p>
<p>我们决定引入非线性函数作为激励函数，这样深层神经网络才有意义（不再是输入的线性组合）。</p>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbzrkldhj30vq0i441l.jpg" alt=""></p>
<a id="more"></a>
<p>本文将介绍深度学习中的4个常见的激活函数，从原函数公式、导数函数及二者的可视化来进行对比：</p>
<ul>
<li>Sigmoid函数</li>
<li>Tanh函数</li>
<li>ReLu函数</li>
<li>Leaky ReLu函数</li>
</ul>
<h2 id="激活函数特征">激活函数特征</h2>
<ol>
<li>非线性：激活函数满足非线性时，才不会被单层网络替代，神经网络才有了意义</li>
<li>可微性：优化器大多数是用梯度下降来更新梯度；如果不可微的话，就不能求导，也就不能更新参数</li>
<li>单调性：激活函数是单调的，能够保证网络的损失函数是凸函数，更容易收敛</li>
</ol>
<h2 id="Sigmoid函数">Sigmoid函数</h2>
<p>表示形式为<code>tf.nn.sigmoid(x)</code></p>
<p>$$f(x)=\frac{1}{1+e^{-x}}$$</p>
<h3 id="原函数">原函数</h3>
<p>In [1]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回sigmoid函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_sigmoid</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = sigmoid(x)</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_sigmoid()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbcpmyecj30ac06wq2z.jpg" alt=""></p>
<h3 id="导数函数">导数函数</h3>
<p>该函数的导数为：</p>
<p>$$\begin{aligned}<br>
f^{\prime}(z) &amp;=\left(\frac{1}{1+e<sup>{-z}}\right)</sup>{\prime} \<br>
&amp;=\frac{e<sup>{-z}}{\left(1+e</sup>{-z}\right)^2} \<br>
&amp;=\frac{1+e<sup>{-z}-1}{\left(1+e</sup>{-z}\right)^2} \<br>
&amp;=\frac{1}{\left(1+e<sup>{-z}\right)}\left(1-\frac{1}{\left(1+e</sup>{-z}\right)}\right) \<br>
&amp;=f(z)(1-f(z))<br>
\end{aligned}<br>
$$</p>
<p>另一种求解方法：</p>
<p>步骤1：</p>
<p>$$\begin{aligned}<br>
\frac{\mathrm{d} y}{\mathrm{~d} x} &amp;=-\left(1+e<sup>{-x}\right)</sup>{-2} \cdot\left(1+e<sup>{-x}\right)</sup>{\prime} \<br>
&amp;=-\left(1+e<sup>{-x}\right)</sup>{-2} \cdot 1 \cdot\left(e<sup>{-x}\right)</sup>{\prime} \<br>
&amp;=-\left(1+e<sup>{-x}\right)</sup>{-2} \cdot 1 \cdot\left(e^{-x}\right) \cdot(-x)^{\prime} \<br>
&amp;=-\left(1+e<sup>{-x}\right)</sup>{-2} \cdot 1 \cdot\left(e^{-x}\right) \cdot(-1) \<br>
&amp;=\left(1+e<sup>{-x}\right)</sup>{-2} \cdot\left(e^{-x}\right) \<br>
&amp;=\frac{e<sup>{-x}}{\left(1+e</sup>{-x}\right)^2}<br>
\end{aligned}$$</p>
<p>步骤2：</p>
<p>$$1-y=1-\frac{1}{1+e<sup>{-x}}=\frac{1+e</sup>{-x}-1}{1+e<sup>{-x}}=\frac{e</sup>{-x}}{1+e^{-x}}$$</p>
<p>步骤3：</p>
<p>$$\frac {dy}{dx}=\frac{e<sup>{-x}}{(1+e</sup>{-x})}  * \frac{1}{(1+e^{-x})}=y(1-y)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">der_sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回sigmoid函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sig = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))  <span class="comment"># sigmoid函数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sig * (<span class="number">1</span> - sig)  <span class="comment"># 输出为导数函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_der_sigmoid</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = der_sigmoid(x)  <span class="comment"># 导数函数</span></span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_der_sigmoid()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbd9ryjdj30ai06wwek.jpg" alt=""></p>
<h3 id="特点">特点</h3>
<p>Sigmoid函数是二分类算法，尤其是逻辑回归中算法中的常用激活函数；也可以作为较少层数的神经网络的激活函数。</p>
<p>它主要是有下面几个特点：</p>
<ol>
<li>能够将自变量𝑋∈𝑅的值全部缩放到(0,1)之间。</li>
<li>当X无穷大的时候，函数值趋于1；X无穷小的时候，趋于0。相当于对输入进行了归一化操作。</li>
<li>该函数是一个连续可导的函数；通过导数函数的图像能够观察到：0点时候，导函数的值最大，并且两边逐渐减小</li>
</ol>
<h3 id="缺陷">缺陷</h3>
<ul>
<li>从导数函数的图像中观察到，X在正无穷大或者负无穷小的时候，导数（梯度）为0，即出现了<strong>梯度弥散</strong>现象；</li>
<li>导数的值在(0,0.25)之间；在多层神经网络中，我们需要对输出层到输入层逐层进行链式求导。这样就导致多个0到0.25之间的小数相乘，造成了结果取0，造成了<strong>梯度消失</strong>。</li>
<li>Sigmod函数存在幂运算，计算复杂度大，训练时间长。</li>
</ul>
<p>下面解释下Sigmoid最为致命的缺点（参考一位网友的回答，解释很全面）</p>
<blockquote>
<p>对于Sigmoid激活函数最致命的缺点就是容易发生<strong>梯度弥散</strong>（Gradient vanishing）现象（当然也可能会发生梯度爆炸Exploding gradient，前面层的梯度通过模型训练变的很大，由于反向传播中链式法则的原因，导致后面层的梯度值会以指数级增大。 但是在Sigmoid激活函数中梯度保障发生的概率非常小），所谓<strong>梯度弥散故名思议就是梯度值越来越小</strong>。</p>
<p>在深度学习中，梯度更新是从后向前更新的，这也就是所谓的反向传播（Backpropagation algorithm），而反向传播的核心是链式法则。如果使用Sigmoid激活函数，训练的网络比较浅还比较好，但是一旦训练较深的神经网络，会导致每次传过来的梯度都会乘上小于1的值，多经过几层之后，梯度就会变得非常非常小（逐渐接近于0），因此<strong>梯度消失</strong>了，对应的参数得不到更新。</p>
<p>参考：<a href="https://zhuanlan.zhihu.com/p/104318223" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/104318223</a></p>
</blockquote>
<p>现在神经网络中很少使用Sigmoid作为激活函数。</p>
<h2 id="tanh函数">tanh函数</h2>
<p>tanh 是一个双曲正切函数。tanh 函数和 sigmoid 函数的曲线相似。</p>
<p>该函数是一个奇函数，经过原点且严格单调递增。函数取值分布在(-1,1)之间。</p>
<h3 id="原函数-v2">原函数</h3>
<p>下面是原函数的具体表达形式，我们还发现tanh函数和sigmoid函数的关系：</p>
<p>$$\tanh x=\frac{\sinh x}{\cosh x}=\frac{e<sup>x-e</sup>{-x}}{e<sup>x+e</sup>{-x}}=\frac{1-e<sup>{-2x}}{1+e</sup>{-2x}}=2<em>Sigmoid(2</em>x)-1$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>)</span><br><span class="line">y = tanh(x)</span><br><span class="line"></span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">ax.set_xticks([<span class="number">-10</span>, <span class="number">-5</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">ax.set_yticks([<span class="number">-1</span>, <span class="number">-0.5</span>, <span class="number">0.5</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, label=<span class="string">"Tanh"</span>, color=<span class="string">"red"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbrp5jubj30iz0ch3ym.jpg" alt=""></p>
<h3 id="导函数">导函数</h3>
<p>下面是具体的求导过程：</p>
<p>$$f(x)=\tanh (x)=\frac{e<sup>x-e</sup>{-x}}{e<sup>x+e</sup>{-x}}$$</p>
<p>首先公布结果，导数函数为：</p>
<p>$$f(x)^{\prime}=1-(\tanh (x))^2$$</p>
<p><strong>下面是具体过程</strong>：</p>
<p>步骤1、在除法的求导公式中有：</p>
<p>$$\left(\frac{\mu}{\nu}\right)<sup>{\prime}=\frac{\mu</sup>{\prime} \nu-\mu \nu<sup>{\prime}}{\nu</sup>2}$$</p>
<p>步骤2、定义两个中间变量：</p>
<p>$$a=e^x$$</p>
<p>$$b=e^{-x}$$</p>
<p>步骤3、第一次求导</p>
<p>$$\left(\frac{e<sup>x-e</sup>{-x}}{e<sup>x+e</sup>{-x}}\right)<sup>{\prime}=\left(\frac{a-b}{a+b}\right)</sup>{\prime}=\frac{(a-b)^{\prime} \times(a+b)-(a-b) \times(a+b)<sup>{\prime}}{(a+b)</sup>2}$$</p>
<p>步骤4、其中有</p>
<p>$$(a-b)<sup>{\prime}=\left(e</sup>x-e<sup>{-x}\right)=e</sup>x-(-1) \times e<sup>{-x}=e</sup>x+e^{-x}$$</p>
<p>$$(a+b)<sup>{\prime}=\left(e</sup>x+e<sup>{-x}\right)=e</sup>x+(-1) \times e<sup>{-x}=e</sup>x-e^{-x}$$</p>
<p>步骤5、将a+b和a-b进行整理：</p>
<p>$$(a-b)<sup>{\prime}=e</sup>{x} + e^{-x} = a+b$$</p>
<p>$$(a+b)<sup>{\prime}=e</sup>{x} - e^{-x} = a-b$$</p>
<p>步骤6、化简上面的结果</p>
<p>$$\begin{array}{l}<br>
\frac{(a-b)^{\prime} \times(a+b)-(a-b) \times(a+b)<sup>{\prime}}{(a+b)</sup>2} \<br>
=\frac{(a+b)<sup>2-(a-b)</sup>2}{(a+b)^2} \<br>
=1-\frac{(a-b)<sup>2}{(a+b)</sup>2} \<br>
=1-\left(\frac{e<sup>x-e</sup>{-x}}{e<sup>x+e</sup>{-x}}\right)^2 \<br>
=1-\operatorname{tanh}(x)^2<br>
\end{array}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制图</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">der_tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    tanh(x)函数的导数求解</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    tanh = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>-tanh ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>)</span><br><span class="line">y = der_tanh(x)</span><br><span class="line"></span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">ax.set_xticks([<span class="number">-10</span>, <span class="number">-5</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">ax.set_yticks([<span class="number">-1</span>, <span class="number">-0.5</span>, <span class="number">0.5</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, label=<span class="string">"der_tanh"</span>, color=<span class="string">"red"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbsgdkaqj30iz0cijri.jpg" alt=""></p>
<h3 id="特点-v2">特点</h3>
<ol>
<li>Tanh函数输出满足0均值；</li>
<li>当输入较大或者较小时，输出的值变化很小，导致导函数几乎为0，也就是梯度很小，从而不利于W、b的值更新（二者的更新都和梯度有关）。</li>
<li>梯度（导数）的取值在（0，1]之间，最大梯度为1，能够保证梯度在变化过程中不削减，缓解了Sigmoid函数梯度消失的问题；但是取值过大或者过小，仍存在梯度消失</li>
<li>同样地函数本身存在幂运算，计算力度大</li>
</ol>
<h2 id="Sigmoid和Tanh关系">Sigmoid和Tanh关系</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span>  <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid函数</span></span><br><span class="line">y = sigmoid(x)</span><br><span class="line"><span class="comment"># tanh函数</span></span><br><span class="line">tanh = <span class="number">2</span>*sigmoid(<span class="number">2</span>*x) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">-11</span>,<span class="number">11</span>)</span><br><span class="line">plt.ylim(<span class="number">-1.1</span>,<span class="number">1.1</span>)</span><br><span class="line"></span><br><span class="line">ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line"></span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>,<span class="number">0</span>))</span><br><span class="line">ax.set_xticks([<span class="number">-10</span>,<span class="number">-5</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>])</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>,<span class="number">0</span>))</span><br><span class="line">ax.set_yticks([<span class="number">-1</span>,<span class="number">-0.5</span>,<span class="number">0.5</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.plot(x,y,label=<span class="string">"Sigmoid"</span>,color = <span class="string">"blue"</span>)</span><br><span class="line"><span class="comment"># tanh函数这里是2*x</span></span><br><span class="line">plt.plot(<span class="number">2</span>*x,tanh,label=<span class="string">"Tanh"</span>, color = <span class="string">"red"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbt1ul49j30fw09gq32.jpg" alt=""></p>
<p>在一般的二分类问题中，Sigmoid函数一般用输出层，而tanh函数一般用于隐藏层（非固定，经验之谈）。</p>
<h2 id="Relu函数">Relu函数</h2>
<p>ReLu函数是目前深度学习中比较流行的一种激活函数。</p>
<h3 id="原函数-v3">原函数</h3>
<p>ReLU函数, 也称之为<strong>线性整流函数(Rectified Linear Unit)</strong>, 是神经网络结构中常用的非线性激活函数。下面是简写形式：</p>
<p>$$f(x)=max(x,0)$$</p>
<p>下面是完整的表达式：</p>
<p>$$\operatorname{ReLU}(x)=\left{\begin{array}{ll}<br>
0, &amp; x \leqslant 0 \<br>
x, &amp; x&gt;0<br>
\end{array}\right.$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回Relu函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 不能直接使用max函数，报错</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_relu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = relu(x)  <span class="comment"># 导数函数</span></span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_relu()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbtmuducj30jj09x0sz.jpg" alt=""></p>
<h3 id="导数函数-v2">导数函数</h3>
<p>$$y<sup>{\prime}=f</sup>{\prime}(x)=\left{\begin{array}{ll}<br>
1, &amp; x&gt;0 \<br>
0, &amp; x \leq 0<br>
\end{array}\right.$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">der_relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回Relu导数函数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 重点：通过numpy的where函数进行判断</span></span><br><span class="line">    <span class="keyword">return</span> np.where(x&gt;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_der_relu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = der_relu(x)  <span class="comment"># 导数函数</span></span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_der_relu()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbuxi7llj30jm09xjrl.jpg" alt=""></p>
<h3 id="特点-v3">特点</h3>
<ol>
<li>函数本身在输入大于为0的时候，输出逐渐增加，这样梯度值也一直存在，从而避免了梯度的饱和：正区间解决梯度消失问题</li>
<li>函数本身是线性函数，比Sigmoid或者Tanh函数要计算速度快；同时函数的收敛速度要大于Sigmoid或者Tanh函数</li>
<li>函数的输出不是以0为均值，收敛慢</li>
<li>Dead Relu问题：在负输入部分，输入的值为0，从而梯度为0，导致参数无法更新，造成神经元死亡；在实际处理中，我们可以减少过多的负数特征进入网络</li>
</ol>
<h2 id="Leaky-ReLu-函数">Leaky ReLu 函数</h2>
<p>Leaky ReLu 函数是为了解决Relu函数负区间的取值为0而产生的。</p>
<p><img src="https://image.jiqizhixin.com/uploads/editor/91a214e0-d773-4ede-be3b-3f046ae5e1d4/640.png" alt=""></p>
<ul>
<li>左：ReLu</li>
<li>右：Leaky ReLu</li>
</ul>
<h3 id="原函数-v4">原函数</h3>
<p>在小于0的部分引入了一个斜率，使得小于0的部分取值不再全部是0（通常 a 的值为 0.01 左右）</p>
<p>$$y=f(x)=\left{\begin{array}{ll}<br>
x, &amp; x&gt;0 \<br>
a \cdot x, &amp; x \leq 0<br>
\end{array}\right.$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回Leaky Relu函数图像</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    a = <span class="number">0.01</span>  <span class="comment"># 斜率a的取值</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(a * x, x)  <span class="comment"># 通过np.maximum函数实现</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_Leaky_relu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = leaky_relu(x)  <span class="comment"># 导数函数</span></span><br><span class="line">    plt.plot(x, y, color=<span class="string">"red"</span>)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_Leaky_relu()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbvkrl3oj30jj09xjrn.jpg" alt=""></p>
<h3 id="导数函数-v3">导数函数</h3>
<p>$$y<code>=f</code>(x)=\left{\begin{array}{ll}<br>
1, &amp; x&gt;0 \<br>
a, &amp; x \leq 0<br>
\end{array}\right.$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">der_leaky_relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    返回Leaky Relu函数图像</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 斜率a的取值</span></span><br><span class="line">    a = <span class="number">0.1</span></span><br><span class="line">    <span class="comment"># 通过where判断来取值</span></span><br><span class="line">    <span class="keyword">return</span> np.where(x&gt;<span class="number">0</span>,<span class="number">1</span>,a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_Leaky_relu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># param:起点，终点，间距</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">    x = np.arange(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = der_leaky_relu(x)  <span class="comment"># 导数函数</span></span><br><span class="line">    plt.plot(x, y, color = <span class="string">"red"</span>)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plot_Leaky_relu()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/008vxvgGly1h7hbvnj3x5j30jm09xaa9.jpg" alt=""></p>
<h3 id="特点-v4">特点</h3>
<ol>
<li>具有和ReLu完全相同的特点，而且不会造成Dead ReLu问题</li>
<li>函数本身的取值在负无穷到正无穷；负区间梯度也存在，从而避免了梯度消失。</li>
<li>但是实际运用中，尚未完全证明 Leaky ReLU 总是比 ReLU 更好。</li>
</ol>

      
    </div>
    
    
    

<div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html">深度学习4大激活函数</a></p>
  <p><span>发布时间:</span>2022年10月25日 - 11:10</p>
  <p><span>原始链接:</span><a href="/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html" title="深度学习4大激活函数">http://www.renpeter.cn/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://www.renpeter.cn/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html"  aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
	  $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
	    });
    });  
</script>

      
</div>


    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Coffee or Tea</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="PiQianChao WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          
            <a href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="tag"># 激活函数</a>
          
            <a href="/tags/%E6%A2%AF%E5%BA%A6/" rel="tag"># 梯度</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/10/23/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.html" rel="next" title="吴恩达深度学习4-梯度下降">
                <i class="fa fa-chevron-left"></i> 吴恩达深度学习4-梯度下降
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/10/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A05%E5%A4%A7%E4%BC%98%E5%8C%96%E5%99%A8.html" rel="prev" title="深度学习5大优化器">
                深度学习5大优化器 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/cunshang.jpg"
                alt="PiQianChao" />
            
              <p class="site-author-name" itemprop="name">PiQianChao</p>
              <p class="site-description motion-element" itemprop="description">My Blog</p>
          </div>
            
           <iframe  frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=694660&auto=1&height=66"></iframe>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">816</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">106</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">154</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/pidada" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:pichaochao1119@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习4大激活函数"><span class="nav-number">1.</span> <span class="nav-text">深度学习4大激活函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数特征"><span class="nav-number">2.</span> <span class="nav-text">激活函数特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid函数"><span class="nav-number">3.</span> <span class="nav-text">Sigmoid函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原函数"><span class="nav-number">3.1.</span> <span class="nav-text">原函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#导数函数"><span class="nav-number">3.2.</span> <span class="nav-text">导数函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点"><span class="nav-number">3.3.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺陷"><span class="nav-number">3.4.</span> <span class="nav-text">缺陷</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tanh函数"><span class="nav-number">4.</span> <span class="nav-text">tanh函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原函数-v2"><span class="nav-number">4.1.</span> <span class="nav-text">原函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#导函数"><span class="nav-number">4.2.</span> <span class="nav-text">导函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-v2"><span class="nav-number">4.3.</span> <span class="nav-text">特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid和Tanh关系"><span class="nav-number">5.</span> <span class="nav-text">Sigmoid和Tanh关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Relu函数"><span class="nav-number">6.</span> <span class="nav-text">Relu函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原函数-v3"><span class="nav-number">6.1.</span> <span class="nav-text">原函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#导数函数-v2"><span class="nav-number">6.2.</span> <span class="nav-text">导数函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-v3"><span class="nav-number">6.3.</span> <span class="nav-text">特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Leaky-ReLu-函数"><span class="nav-number">7.</span> <span class="nav-text">Leaky ReLu 函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原函数-v4"><span class="nav-number">7.1.</span> <span class="nav-text">原函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#导数函数-v3"><span class="nav-number">7.2.</span> <span class="nav-text">导数函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-v4"><span class="nav-number">7.3.</span> <span class="nav-text">特点</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

	
	
		<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
		<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
		<div class="widget-wrap">
			<h3 class="widget-title">标签云</h3>
			<div id="myCanvasContainer" class="widget tagcloud">
			<canvas width="250" height="250" id="resCanvas" style="width=100%">
				 <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSV/" rel="tag">CSV</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CV/" rel="tag">CV</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EDA/" rel="tag">EDA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JJ/" rel="tag">JJ</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jieba/" rel="tag">Jieba</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KDE/" rel="tag">KDE</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kats/" rel="tag">Kats</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LaTex/" rel="tag">LaTex</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LeetCode/" rel="tag">LeetCode</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MSE/" rel="tag">MSE</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/" rel="tag">MySQL</a><span class="tag-list-count">67</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NN/" rel="tag">NN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCA/" rel="tag">PCA</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/d3/" rel="tag">d3</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dash/" rel="tag">dash</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/" rel="tag">go</a><span class="tag-list-count">42</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/group/" rel="tag">group</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/highcharts/" rel="tag">highcharts</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/json/" rel="tag">json</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jupyter/" rel="tag">jupyter</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kaggle/" rel="tag">kaggle</a><span class="tag-list-count">24</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/keras/" rel="tag">keras</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/" rel="tag">markdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/" rel="tag">matplotlib</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a><span class="tag-list-count">151</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plotly/" rel="tag">plotly</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/px/" rel="tag">px</a><span class="tag-list-count">35</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyecharts/" rel="tag">pyecharts</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyg2plot/" rel="tag">pyg2plot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">97</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/seaborn/" rel="tag">seaborn</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shap/" rel="tag">shap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/" rel="tag">spider</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sql/" rel="tag">sql</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlzoo/" rel="tag">sqlzoo</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tableau/" rel="tag">tableau</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/uci/" rel="tag">uci</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/" rel="tag">二分类</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%92%E8%81%94%E7%BD%91/" rel="tag">互联网</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%A7%E5%93%81/" rel="tag">产品</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%98%E5%8C%96%E5%99%A8/" rel="tag">优化器</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/" rel="tag">公众号</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/" rel="tag">关联分析</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C/" rel="tag">写作</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E7%B1%BB/" rel="tag">分类</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8C%BA%E5%9F%9F%E9%93%BE/" rel="tag">区域链</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%B7%E7%A7%AF/" rel="tag">卷积</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">卷积神经网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AC%E5%9B%9E%E7%8E%87/" rel="tag">召回率</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a><span class="tag-list-count">125</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/" rel="tag">可解释性</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/" rel="tag">吴恩达</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BD%92/" rel="tag">回归</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" rel="tag">回归分析</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E9%87%91/" rel="tag">基金</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a><span class="tag-list-count">48</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A9%E6%B1%A0/" rel="tag">天池</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E5%85%B8/" rel="tag">字典</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8/" rel="tag">容器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%BC%E6%95%B0/" rel="tag">导数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B2%AD%E5%9B%9E%E5%BD%92/" rel="tag">岭回归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BB%BA%E6%A8%A1/" rel="tag">建模</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%80%E6%BA%90/" rel="tag">开源</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/" rel="tag">异常检测</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%A0%E9%87%8F/" rel="tag">张量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BD%92%E4%B8%80%E5%8C%96/" rel="tag">归一化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AA%E7%8E%AF/" rel="tag">循环</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%84%9F%E5%8F%97%E9%87%8E/" rel="tag">感受野</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%88%90%E9%95%BF/" rel="tag">成长</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%95%E8%B5%84/" rel="tag">投资</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%BD%E6%A0%B7/" rel="tag">抽样</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag">推荐系统</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" rel="tag">支持向量机</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag">数学</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a><span class="tag-list-count">90</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" rel="tag">数据处理</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a><span class="tag-list-count">104</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag">数据挖掘</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/" rel="tag">数据探索</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/" rel="tag">文本处理</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%85%E6%B8%B8/" rel="tag">旅游</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3/" rel="tag">无监督</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">无监督学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" rel="tag">时序分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" rel="tag">时间序列</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">142</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9D%8E%E6%B2%90/" rel="tag">李沐</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%91%E6%A8%A1%E5%9E%8B/" rel="tag">树模型</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A2%AF%E5%BA%A6/" rel="tag">梯度</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="tag">梯度下降</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AC%A0%E9%87%87%E6%A0%B7/" rel="tag">欠采样</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AD%A3%E5%88%99%E5%8C%96/" rel="tag">正则化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%A0%E5%8C%96/" rel="tag">池化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%9C%B3/" rel="tag">深圳</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">44</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E6%BC%82/" rel="tag">深漂</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="tag">激活函数</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%9B%E5%AE%A2/" rel="tag">牛客</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/" rel="tag">特征编码</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%8B%AC%E7%83%AD%E7%A0%81/" rel="tag">独热码</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%9F%E6%B4%BB/" rel="tag">生活</a><span class="tag-list-count">50</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%B5%E5%BD%B1/" rel="tag">电影</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">监督学习</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%B8%E5%85%B3%E6%80%A7/" rel="tag">相关性</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/" rel="tag">相关系数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/" rel="tag">矩阵运算</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E5%85%83/" rel="tag">神经元</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A6%BB%E6%95%A3%E5%8C%96/" rel="tag">离散化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%AF%E5%88%86/" rel="tag">积分</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/" rel="tag">窗口函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AB%9E%E8%B5%9B/" rel="tag">竞赛</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B2%BE%E5%BA%A6/" rel="tag">精度</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B4%A2%E5%BC%95/" rel="tag">索引</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E/" rel="tag">经济</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1/" rel="tag">统计</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A0%81/" rel="tag">编码</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B/" rel="tag">编程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%BB%9C/" rel="tag">网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BE%8E%E9%A3%9F/" rel="tag">美食</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%81%9A%E7%B1%BB/" rel="tag">聚类</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/" rel="tag">自动化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86/" rel="tag">自我管理</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag">自然语言处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/" rel="tag">计算机</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%8D%E4%BA%91%E5%9B%BE/" rel="tag">词云图</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E8%90%A5/" rel="tag">运营</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag">逻辑回归</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB/" rel="tag">阅读</a><span class="tag-list-count">28</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%99%8D%E7%BB%B4/" rel="tag">降维</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" rel="tag">随机森林</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%90%E8%97%8F%E5%B1%82/" rel="tag">隐藏层</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" rel="tag">集成学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%92%E6%98%A5/" rel="tag">青春</a><span class="tag-list-count">1</span></li></ul>
			</canvas>
			</div>
		</div>
	

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PiQianChao</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共1238k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="true"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://pidada.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://www.renpeter.cn/2022/10/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html';
          this.page.identifier = '2022/10/25/深度学习4大激活函数.html';
          this.page.title = '深度学习4大激活函数';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://pidada.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script>


  




<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


</body>
</html>
